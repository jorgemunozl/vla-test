{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98303157",
   "metadata": {},
   "source": [
    "# Five Test\n",
    "\n",
    "Until know we are just using the first frame to predict a task, but VLA's consider more than one just frame to generate an action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079be204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c3525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip install \"git+https://github.com/huggingface/transformers.git@fix/lerobot_openpi\" \"lerobot @ git+https://github.com/huggingface/lerobot.git\" opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a71792b",
   "metadata": {},
   "source": [
    "Use our modified version from the Pi 0.5 Model [from this repo.](https://github.com/NONHUMAN-SITE/XHUMAN.git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0fbbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install \"git+https://github.com/NONHUMAN-SITE/XHUMAN.git#egg=XHUMAN[pi]\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6239beb5",
   "metadata": {},
   "source": [
    "#### Data Set\n",
    "\n",
    "We are going to use the `NONHUMAN_RESEARCH/TEST_RECORD_ANNOTATIONS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77597765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.datasets.lerobot_dataset import LeRobotDataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = LeRobotDataset(\n",
    "    repo_id=\"NONHUMAN-RESEARCH/TEST_RECORD_ANNOTATIONS\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c0ca36",
   "metadata": {},
   "source": [
    "### Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161eee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xhuman.scripts.pi05.modeling_pi_05 import PI05Policy\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   \n",
    "\n",
    "policy = PI05Policy.from_pretrained(\"lerobot/pi05_base\")\n",
    "policy.eval()\n",
    "policy.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668235df",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/paligemma-3b-pt-224\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd08063c",
   "metadata": {},
   "source": [
    "# Some how\n",
    "\n",
    "Now some how use this data set as source of images and propioceptice state, somehow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d9dbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 10\n",
    "for i in range(steps):\n",
    "    # Run policy\n",
    "\n",
    "    \n",
    "    # When the condition for generate the subtask \n",
    "    # Detokenize sub task\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
