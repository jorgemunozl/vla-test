{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Batch - Devuelve un batch del tipo que next(dl_iter) devuelve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (3.13.11) (Python 3.13.11)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/jorge/project/XHUMAN/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import DistributedDataParallelKwargs\n",
    "\n",
    "from lerobot.configs import parser\n",
    "from lerobot.datasets.sampler import EpisodeAwareSampler\n",
    "from lerobot.datasets.utils import cycle\n",
    "\n",
    "from xhuman.configs.train import TrainPipelineConfigXHUMAN\n",
    "from xhuman.datasets.factory import make_dataset_xhuman\n",
    "from xhuman.datasets.utils import split_train_eval_episodes\n",
    "from xhuman.policies.factory import make_xhuman_policy, make_xhuman_pre_post_processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci\u00f3n manual (ajusta seg\u00fan necesites)\n",
    "from xhuman.configs.default import LerobotDatasetConfig\n",
    "from xhuman.policies.pi05.configuration_pi05 import PI05Config\n",
    "\n",
    "# Crear config del dataset\n",
    "dataset_config = LerobotDatasetConfig(\n",
    "    repo_id=\"tu_repo_id/aqui\",  # Cambia esto\n",
    "    root=None,  # o ruta local si tienes el dataset descargado\n",
    ")\n",
    "\n",
    "# Crear config de la policy\n",
    "policy_config = PI05Config(\n",
    "    pretrained_path=None,  # o ruta a checkpoint si tienes uno\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "\n",
    "# Crear config de entrenamiento\n",
    "cfg = TrainPipelineConfigXHUMAN(\n",
    "    dataset=dataset_config,\n",
    "    policy=policy_config,\n",
    "    batch_size=8,\n",
    "    num_workers=4,\n",
    "    split_ratio=0.8,\n",
    ")\n",
    "\n",
    "cfg.validate()\n",
    "device = torch.device(policy_config.device if policy_config.device else \"cuda\" if torch.cuda.is_available() else \"cpu\")",
    "\n",
    "# Crear accelerator (igual que en train_val_pi05.py)\n",
    "ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)\n",
    "accelerator = Accelerator(step_scheduler_with_optimizer=False, kwargs_handlers=[ddp_kwargs])\n",
    "device = accelerator.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset siguiendo el patr\u00f3n de train_val_pi05.py\n",
    "# Primero cargar dataset completo para obtener total_episodes\n",
    "dataset = make_dataset_xhuman(cfg)\n",
    "episodes = list(range(dataset.meta.total_episodes))\n",
    "train_episodes, _ = split_train_eval_episodes(episodes, split_ratio=cfg.split_ratio, seed=42)\n",
    "if 30 in train_episodes:\n",
    "    train_episodes.remove(30)\n",
    "\n",
    "# Eliminar dataset para liberar memoria (igual que en train_val_pi05.py)\n",
    "del dataset\n",
    "\n",
    "# Crear dataset solo con train_episodes\n",
    "cfg.dataset.episodes = train_episodes\n",
    "dataset = make_dataset_xhuman(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear policy y preprocessor\n",
    "policy = make_xhuman_policy(cfg=cfg.policy, ds_meta=dataset.meta)\n",
    "processor_kwargs = {\"dataset_stats\": dataset.meta.stats}\n",
    "if cfg.policy.pretrained_path is not None:\n",
    "    processor_kwargs[\"preprocessor_overrides\"] = {\n",
    "        \"device_processor\": {\"device\": device.type},\n",
    "        \"normalizer_processor\": {\n",
    "            \"stats\": dataset.meta.stats,\n",
    "            \"features\": {**policy.config.input_features, **policy.config.output_features},\n",
    "            \"norm_map\": policy.config.normalization_mapping,\n",
    "        },\n",
    "    }\n",
    "preprocessor, _ = make_xhuman_pre_post_processors(\n",
    "    policy_cfg=cfg.policy,\n",
    "    pretrained_path=cfg.policy.pretrained_path,\n",
    "    **processor_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dataloader\n",
    "if hasattr(cfg.policy, \"drop_n_last_frames\"):\n",
    "    sampler = EpisodeAwareSampler(\n",
    "        dataset.meta.episodes[\"dataset_from_index\"],\n",
    "        dataset.meta.episodes[\"dataset_to_index\"],\n",
    "        drop_n_last_frames=cfg.policy.drop_n_last_frames,\n",
    "        shuffle=True,\n",
    "    )\n",
    "else:\n",
    "    sampler = None\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=cfg.num_workers,\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=(sampler is None) and not cfg.dataset.streaming,\n",
    "    sampler=sampler,\n",
    "    pin_memory=device.type == \"cuda\",\n",
    "    drop_last=False,\n",
    "    prefetch_factor=2 if cfg.num_workers > 0 else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dataloader con accelerator (igual que en train_val_pi05.py)\n",
    "# Nota: solo preparamos el dataloader, no policy ni optimizer ya que no los necesitamos\n",
    "dataloader = accelerator.prepare(dataloader)\n",
    "dl_iter = cycle(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener batch procesado (igual que next(dl_iter) en train_val_pi05.py)\n",
    "batch = next(dl_iter)\n",
    "batch = preprocessor(batch)\n",
    "\n",
    "# El batch est\u00e1 listo para usar\n",
    "print(\"Batch keys:\", list(batch.keys()))\n",
    "for key, value in batch.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"  {key}: shape={value.shape}, dtype={value.dtype}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}