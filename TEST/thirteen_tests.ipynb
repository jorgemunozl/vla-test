{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jorgemunozl/vla-test/blob/main/TEST/thirteen_tests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zFwCuxqMnv8"
      },
      "source": [
        "# Thirteen Test - Test our processor, CUDA nedded?\n",
        "\n",
        "Let's see if our processor is good."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3_JMdiPmkA9"
      },
      "source": [
        "## Setup\n",
        "\n",
        "The following cells set up the environment:\n",
        "1. Clone the XHUMAN repository\n",
        "2. Install dependencies\n",
        "3. Authenticate with HuggingFace Hub\n",
        "4. Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wgo2DrQ1wF5C"
      },
      "outputs": [],
      "source": [
        "# Clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFr64v0rwSM8",
        "outputId": "f9e52684-aa68-4eb6-c6b6-fc224f4a119b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/XHUMAN\n"
          ]
        }
      ],
      "source": [
        "%cd XHUMAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljAwUMsOwm9P",
        "outputId": "5960d27f-0c47-4d71-d7c1-5596aab675d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m215 packages\u001b[0m \u001b[2min 30.67s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m45 packages\u001b[0m \u001b[2min 21.44s\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m14 packages\u001b[0m \u001b[2min 969ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m45 packages\u001b[0m \u001b[2min 250ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1masync-lru\u001b[0m\u001b[2m==2.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mav\u001b[0m\u001b[2m==15.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcomm\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdeepdiff\u001b[0m\u001b[2m==8.6.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mdiffusers\u001b[0m\u001b[2m==0.36.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdiffusers\u001b[0m\u001b[2m==0.35.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdraccus\u001b[0m\u001b[2m==0.10.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mevdev\u001b[0m\u001b[2m==1.9.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfaker\u001b[0m\u001b[2m==40.1.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfeetech-servo-sdk\u001b[0m\u001b[2m==1.0.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.36.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.35.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1minquirerpy\u001b[0m\u001b[2m==0.3.4\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mipykernel\u001b[0m\u001b[2m==6.17.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mipykernel\u001b[0m\u001b[2m==7.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjson5\u001b[0m\u001b[2m==0.13.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjsonlines\u001b[0m\u001b[2m==4.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyter\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mjupyter-client\u001b[0m\u001b[2m==7.4.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyter-client\u001b[0m\u001b[2m==8.8.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyter-lsp\u001b[0m\u001b[2m==2.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyterlab\u001b[0m\u001b[2m==4.5.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyterlab-server\u001b[0m\u001b[2m==2.28.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlerobot\u001b[0m\u001b[2m==0.4.4 (from git+https://github.com/huggingface/lerobot.git@6d34a986de44c5f22a9a99ed514f1b16832c3f32)\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmergedeep\u001b[0m\u001b[2m==1.3.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmypy-extensions\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnotebook\u001b[0m\u001b[2m==6.5.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnotebook\u001b[0m\u001b[2m==7.5.2\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.10.2.21\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.5.1.17\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.27.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.26.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1morderly-set\u001b[0m\u001b[2m==5.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpfzy\u001b[0m\u001b[2m==0.3.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpiper-sdk\u001b[0m\u001b[2m==0.6.1 (from git+https://github.com/agilexrobotics/piper_sdk.git@081e7c588e5b79eeaefa67a0469bcc701c81014f)\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpynput\u001b[0m\u001b[2m==1.8.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyserial\u001b[0m\u001b[2m==3.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-can\u001b[0m\u001b[2m==4.6.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-xlib\u001b[0m\u001b[2m==0.33\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyyaml-include\u001b[0m\u001b[2m==1.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrerun-sdk\u001b[0m\u001b[2m==0.26.2\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.22.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.21.4\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.9.0+cu126\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchcodec\u001b[0m\u001b[2m==0.5\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.24.0+cu126\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.22.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.57.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.53.3 (from git+https://github.com/huggingface/transformers.git@dcddb970176382c0fcf4521b0c0e6fc15894dfe0)\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-inspect\u001b[0m\u001b[2m==0.9.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mwrapt\u001b[0m\u001b[2m==2.0.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwrapt\u001b[0m\u001b[2m==1.17.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mxhuman\u001b[0m\u001b[2m==0.1.0 (from file:///content/XHUMAN)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!uv pip install -e .[pi]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7zILqJ7Wv8rz"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from contextlib import nullcontext\n",
        "from typing import Any\n",
        "\n",
        "import torch\n",
        "from accelerate import Accelerator\n",
        "from accelerate.utils import DistributedDataParallelKwargs\n",
        "from torch.optim import Optimizer\n",
        "\n",
        "from lerobot.configs import parser\n",
        "from lerobot.datasets.sampler import EpisodeAwareSampler\n",
        "from lerobot.datasets.utils import cycle\n",
        "from lerobot.optim.factory import make_optimizer_and_scheduler\n",
        "from lerobot.policies.pretrained import PreTrainedPolicy\n",
        "from lerobot.utils.logging_utils import AverageMeter, MetricsTracker\n",
        "from lerobot.utils.random_utils import set_seed\n",
        "from lerobot.utils.train_utils import load_training_state\n",
        "from lerobot.utils.utils import (\n",
        "    format_big_number,\n",
        "    has_method,\n",
        "    init_logging,\n",
        ")\n",
        "\n",
        "from xhuman.policies.factory import make_xhuman_policy, make_xhuman_pre_post_processors\n",
        "from xhuman.configs.train import TrainPipelineConfigXHUMAN\n",
        "from xhuman.datasets.factory import make_dataset_xhuman\n",
        "from xhuman.datasets.utils import split_train_eval_episodes\n",
        "from xhuman.logger import logger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYlyeGygv8r0"
      },
      "source": [
        "## Helper Functions\n",
        "\n",
        "These functions handle dataset loading and policy updates. They are designed to work with distributed training using HuggingFace Accelerate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CVmBxC-hv8r1"
      },
      "outputs": [],
      "source": [
        "def load_dataset(cfg: TrainPipelineConfigXHUMAN, episodes: list[int], is_main_process: bool = True, accelerator: Accelerator | None = None):\n",
        "    \"\"\"\n",
        "    Load the dataset for training and evaluation.\n",
        "    \"\"\"\n",
        "    # Dataset loading synchronization: main process downloads first to avoid race conditions\n",
        "    cfg.dataset.episodes = episodes\n",
        "\n",
        "    if is_main_process:\n",
        "        logger.info(\"Creating dataset\")\n",
        "        dataset = make_dataset_xhuman(cfg)\n",
        "\n",
        "    accelerator.wait_for_everyone()\n",
        "\n",
        "    # Now all other processes can safely load the dataset\n",
        "    if not is_main_process:\n",
        "        dataset = make_dataset_xhuman(cfg)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lK93NSNOuXsi"
      },
      "outputs": [],
      "source": [
        "from xhuman.policies.pi05ki.configuration_pi05ki import PI05KIConfig\n",
        "\n",
        "policy_config = PI05KIConfig(repo_id=\"none\",device=\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipXWi5oev8r2"
      },
      "source": [
        "## Configuration and Setup\n",
        "\n",
        "Configure your dataset and policy settings here. The dataset configuration specifies which HuggingFace repository to load, and the policy configuration sets up the PI05 model architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XEbEEWDbzMPT"
      },
      "outputs": [],
      "source": [
        "from xhuman.configs.default import LerobotDatasetConfig\n",
        "\n",
        "dataset_config = LerobotDatasetConfig(\n",
        "    repo_id=\"NONHUMAN-RESEARCH/test-general-idx\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IZ1d9a3Ov8r3"
      },
      "outputs": [],
      "source": [
        "\n",
        "cfg = TrainPipelineConfigXHUMAN(\n",
        "    dataset=dataset_config,\n",
        "    policy=policy_config # Example policy configuration, replace with your actual policy path\n",
        ")\n",
        "cfg.validate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgSIm33Qv8r3"
      },
      "source": [
        "## Training Setup\n",
        "\n",
        "Initialize the Accelerator for distributed training and set up the training environment. The accelerator automatically handles:\n",
        "- Multi-GPU training\n",
        "- Mixed precision training\n",
        "- Gradient synchronization across processes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XOJhp41Sv8r4"
      },
      "outputs": [],
      "source": [
        "# Create Accelerator\n",
        "# It will automatically detect if running in distributed mode or single-process mode\n",
        "# We set step_scheduler_with_optimizer=False to prevent accelerate from adjusting the lr_scheduler steps based on the num_processes\n",
        "# We set find_unused_parameters=True to handle models with conditional computation\n",
        "ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)\n",
        "accelerator = Accelerator(step_scheduler_with_optimizer=False, kwargs_handlers=[ddp_kwargs])\n",
        "\n",
        "init_logging(accelerator=accelerator)\n",
        "\n",
        "# Determine if this is the main process (for logging and checkpointing)\n",
        "is_main_process = accelerator.is_main_process\n",
        "\n",
        "# Set seed if specified\n",
        "if cfg.seed is not None:\n",
        "    set_seed(cfg.seed, accelerator=accelerator)\n",
        "\n",
        "# Use accelerator's device\n",
        "device = accelerator.device\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cuda.matmul.allow_tf32 = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "s_gB_Dpbv8r5",
        "outputId": "9fed2eda-9ec4-4764-96d3-4b7abd5a3f60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Dataset loading failed with strict features (ValueError). Retrying without features constraint.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[19:51:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Total episodes available: \u001b[1;36m437\u001b[0m                                     \u001b]8;id=230283;file:///tmp/ipython-input-426660049.py\u001b\\\u001b[2mipython-input-426660049.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=717870;file:///tmp/ipython-input-426660049.py#26\u001b\\\u001b[2m26\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:51:17] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Total episodes available: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">437</span>                                     <a href=\"file:///tmp/ipython-input-426660049.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-426660049.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-426660049.py#26\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">26</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m DEBUG MODE: Using only \u001b[1;36m3\u001b[0m episodes                                 \u001b]8;id=240174;file:///tmp/ipython-input-426660049.py\u001b\\\u001b[2mipython-input-426660049.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=861722;file:///tmp/ipython-input-426660049.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> DEBUG MODE: Using only <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> episodes                                 <a href=\"file:///tmp/ipython-input-426660049.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-426660049.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-426660049.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Loading train dataset with \u001b[1;36m2\u001b[0m episodes                             \u001b]8;id=146316;file:///tmp/ipython-input-426660049.py\u001b\\\u001b[2mipython-input-426660049.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=772246;file:///tmp/ipython-input-426660049.py#50\u001b\\\u001b[2m50\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Loading train dataset with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> episodes                             <a href=\"file:///tmp/ipython-input-426660049.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-426660049.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-426660049.py#50\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">50</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Creating dataset                                                  \u001b]8;id=571858;file:///tmp/ipython-input-1989669429.py\u001b\\\u001b[2mipython-input-1989669429.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=91161;file:///tmp/ipython-input-1989669429.py#9\u001b\\\u001b[2m9\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Creating dataset                                                  <a href=\"file:///tmp/ipython-input-1989669429.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-1989669429.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-1989669429.py#9\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">9</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Dataset loading failed with strict features (ValueError). Retrying without features constraint.\n"
          ]
        }
      ],
      "source": [
        "import lerobot.datasets.lerobot_dataset\n",
        "from lerobot.datasets.utils import load_nested_dataset as original_load_nested_dataset\n",
        "import datasets\n",
        "\n",
        "# Monkey patch to handle schema mismatch\n",
        "# The dataset parquet files have a schema that conflicts with the strict fixed-length definition\n",
        "# expected by the code. We patch the loader to ignore strict features if loading fails.\n",
        "def patched_load_nested_dataset(pq_dir, features=None, episodes=None):\n",
        "    try:\n",
        "        return original_load_nested_dataset(pq_dir, features=features, episodes=episodes)\n",
        "    except (datasets.builder.DatasetGenerationError, datasets.table.CastError, Exception) as e:\n",
        "        # Fallback if strict schema casting fails\n",
        "        print(f\"Warning: Dataset loading failed with strict features ({type(e).__name__}). Retrying without features constraint.\")\n",
        "        return original_load_nested_dataset(pq_dir, features=None, episodes=episodes)\n",
        "\n",
        "lerobot.datasets.lerobot_dataset.load_nested_dataset = patched_load_nested_dataset\n",
        "\n",
        "DEBUG_MODE = True  # Set to False for full training\n",
        "DEBUG_MAX_EPISODES = 3  # Use only first N episodes for debugging\n",
        "\n",
        "# First, get total episodes count (load minimal dataset to check)\n",
        "if is_main_process:\n",
        "    temp_dataset = make_dataset_xhuman(cfg)\n",
        "    total_episodes = temp_dataset.meta.total_episodes\n",
        "    del temp_dataset\n",
        "    logger.info(f\"Total episodes available: {total_episodes}\")\n",
        "else:\n",
        "    # For non-main processes, use a reasonable default\n",
        "    # In practice, this will be synced after main process loads\n",
        "    total_episodes = 4  # Fallback - adjust if needed\n",
        "\n",
        "accelerator.wait_for_everyone()\n",
        "\n",
        "# Limit episodes for debugging\n",
        "if DEBUG_MODE:\n",
        "    episodes = list(range(min(DEBUG_MAX_EPISODES, total_episodes)))\n",
        "    if is_main_process:\n",
        "        logger.info(f\"DEBUG MODE: Using only {len(episodes)} episodes\")\n",
        "else:\n",
        "    episodes = list(range(total_episodes))\n",
        "\n",
        "# Split episodes\n",
        "train_episodes, eval_episodes = split_train_eval_episodes(\n",
        "    episodes, split_ratio=cfg.split_ratio, seed=42\n",
        ")\n",
        "\n",
        "# Load dataset with ONLY train episodes (proper way to filter)\n",
        "# This uses the load_dataset helper function which sets cfg.dataset.episodes\n",
        "if is_main_process:\n",
        "    logger.info(f\"Loading train dataset with {len(train_episodes)} episodes\")\n",
        "dataset = load_dataset(cfg, train_episodes, is_main_process=is_main_process, accelerator=accelerator)\n",
        "dataset.train_with_subtasks = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WeVjdudv8r6"
      },
      "source": [
        "## Dataset and Model Information\n",
        "\n",
        "Display metadata about the loaded dataset and model. This includes:\n",
        "- Total number of episodes and frames\n",
        "- Model parameter counts\n",
        "- Effective batch size (accounting for distributed training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4cFEE9pv8r6",
        "outputId": "4f1318b0-6794-43bb-9093-e522334fe6bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "DATASET METADATA\n",
            "================================================================================\n",
            "\n",
            "Dataset Repository: NONHUMAN-RESEARCH/test-general-idx\n",
            "Total Episodes: 437\n",
            "Training Episodes: 2\n",
            "Number of Frames: 2,251\n",
            "Number of Episodes (loaded): 2\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Display dataset metadata and model configuration\n",
        "if is_main_process:\n",
        "    from pprint import pprint\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"DATASET METADATA\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"\\nDataset Repository: {dataset.repo_id}\")\n",
        "    print(f\"Total Episodes: {dataset.meta.total_episodes}\")\n",
        "    print(f\"Training Episodes: {len(train_episodes)}\")\n",
        "    print(f\"Number of Frames: {dataset.num_frames:,}\")\n",
        "    print(f\"Number of Episodes (loaded): {dataset.num_episodes}\")\n",
        "\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "rcEUR_P1v8r7"
      },
      "outputs": [],
      "source": [
        "# Create processors\n",
        "preprocessor, postprocessor = make_xhuman_pre_post_processors(\n",
        "    policy_cfg=cfg.policy,\n",
        "    pretrained_path=cfg.policy.pretrained_path,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "E_d1t5DWv8r8",
        "outputId": "f303401d-6b76-44f2-c0ab-08bc0551b916"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[20:15:21]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Output dir: outputs/train/\u001b[1;36m2026\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m22\u001b[0m/\u001b[1;36m19\u001b[0m-\u001b[1;36m39\u001b[0m-50_pi05_ki             \u001b]8;id=584004;file:///tmp/ipython-input-1805760154.py\u001b\\\u001b[2mipython-input-1805760154.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=230283;file:///tmp/ipython-input-1805760154.py#3\u001b\\\u001b[2m3\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:15:21] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Output dir: outputs/train/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2026</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39</span>-50_pi05_ki             <a href=\"file:///tmp/ipython-input-1805760154.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-1805760154.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-1805760154.py#3\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Steps: \u001b[1;36m100000\u001b[0m \u001b[1m(\u001b[0m100K\u001b[1m)\u001b[0m                                              \u001b]8;id=813694;file:///tmp/ipython-input-1805760154.py\u001b\\\u001b[2mipython-input-1805760154.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=58655;file:///tmp/ipython-input-1805760154.py#4\u001b\\\u001b[2m4\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Steps: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100000</span> <span style=\"font-weight: bold\">(</span>100K<span style=\"font-weight: bold\">)</span>                                              <a href=\"file:///tmp/ipython-input-1805760154.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-1805760154.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-1805760154.py#4\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Dataset frames: \u001b[1;36m2251\u001b[0m \u001b[1m(\u001b[0m2K\u001b[1m)\u001b[0m                                         \u001b]8;id=330776;file:///tmp/ipython-input-1805760154.py\u001b\\\u001b[2mipython-input-1805760154.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=420651;file:///tmp/ipython-input-1805760154.py#5\u001b\\\u001b[2m5\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Dataset frames: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2251</span> <span style=\"font-weight: bold\">(</span>2K<span style=\"font-weight: bold\">)</span>                                         <a href=\"file:///tmp/ipython-input-1805760154.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-1805760154.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-1805760154.py#5\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Dataset episodes: \u001b[1;36m2\u001b[0m                                               \u001b]8;id=988712;file:///tmp/ipython-input-1805760154.py\u001b\\\u001b[2mipython-input-1805760154.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=594731;file:///tmp/ipython-input-1805760154.py#6\u001b\\\u001b[2m6\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Dataset episodes: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                                               <a href=\"file:///tmp/ipython-input-1805760154.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-1805760154.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-1805760154.py#6\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Effective batch size: \u001b[1;36m8\u001b[0m x \u001b[1;36m1\u001b[0m = \u001b[1;36m8\u001b[0m                                   \u001b]8;id=687277;file:///tmp/ipython-input-1805760154.py\u001b\\\u001b[2mipython-input-1805760154.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=523481;file:///tmp/ipython-input-1805760154.py#9\u001b\\\u001b[2m9\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Effective batch size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> x <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>                                   <a href=\"file:///tmp/ipython-input-1805760154.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-1805760154.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-1805760154.py#9\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">9</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Print training info\n",
        "if is_main_process:\n",
        "    logger.info(f\"Output dir: {cfg.output_dir}\")\n",
        "    logger.info(f\"Steps: {cfg.steps} ({format_big_number(cfg.steps)})\")\n",
        "    logger.info(f\"Dataset frames: {dataset.num_frames} ({format_big_number(dataset.num_frames)})\")\n",
        "    logger.info(f\"Dataset episodes: {dataset.num_episodes}\")\n",
        "    num_processes = accelerator.num_processes\n",
        "    effective_bs = cfg.batch_size * num_processes\n",
        "    logger.info(f\"Effective batch size: {cfg.batch_size} x {num_processes} = {effective_bs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "jAOHZFNwv8r8",
        "outputId": "2184426e-98de-4aed-a3b0-adecfc788961"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[20:15:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Not dropping any frames                                           \u001b]8;id=481141;file:///tmp/ipython-input-988475408.py\u001b\\\u001b[2mipython-input-988475408.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=149811;file:///tmp/ipython-input-988475408.py#12\u001b\\\u001b[2m12\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:15:22] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Not dropping any frames                                           <a href=\"file:///tmp/ipython-input-988475408.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-988475408.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-988475408.py#12\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create dataloader\n",
        "if hasattr(cfg.policy, \"drop_n_last_frames\"):\n",
        "    logger.info(f\"Dropping {cfg.policy.drop_n_last_frames} last frames\")\n",
        "    shuffle = False\n",
        "    sampler = EpisodeAwareSampler(\n",
        "        dataset.meta.episodes[\"dataset_from_index\"],\n",
        "        dataset.meta.episodes[\"dataset_to_index\"],\n",
        "        drop_n_last_frames=cfg.policy.drop_n_last_frames,\n",
        "        shuffle=True,\n",
        "    )\n",
        "else:\n",
        "    logger.info(\"Not dropping any frames\")\n",
        "    shuffle = True\n",
        "    sampler = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "n7wHY5Q_7EMt",
        "outputId": "df7c3eb4-a778-4802-b3d8-e961e661e3c4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[20:15:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Start offline training on a fixed dataset                         \u001b]8;id=588637;file:///tmp/ipython-input-2557974599.py\u001b\\\u001b[2mipython-input-2557974599.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=565158;file:///tmp/ipython-input-2557974599.py#4\u001b\\\u001b[2m4\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:15:25] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Start offline training on a fixed dataset                         <a href=\"file:///tmp/ipython-input-2557974599.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-2557974599.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-2557974599.py#4\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Train episodes: \u001b[1;36m2\u001b[0m                                                 \u001b]8;id=941435;file:///tmp/ipython-input-2557974599.py\u001b\\\u001b[2mipython-input-2557974599.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=611878;file:///tmp/ipython-input-2557974599.py#5\u001b\\\u001b[2m5\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Train episodes: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                                                 <a href=\"file:///tmp/ipython-input-2557974599.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-2557974599.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-2557974599.py#5\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Total training steps: \u001b[1;36m100000\u001b[0m                                      \u001b]8;id=534277;file:///tmp/ipython-input-2557974599.py\u001b\\\u001b[2mipython-input-2557974599.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=517488;file:///tmp/ipython-input-2557974599.py#6\u001b\\\u001b[2m6\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Total training steps: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100000</span>                                      <a href=\"file:///tmp/ipython-input-2557974599.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-2557974599.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-2557974599.py#6\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Training initialization\n",
        "# This logs the start of training and shows how many episodes will be used\n",
        "if is_main_process:\n",
        "    logger.info(\"Start offline training on a fixed dataset\")\n",
        "    logger.info(f\"Train episodes: {len(train_episodes)}\")\n",
        "    logger.info(f\"Total training steps: {cfg.steps}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "ky4jT3NIXSMO"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SmartSubset(Dataset):\n",
        "    def __init__(self, dataset, indices):\n",
        "        self.dataset = dataset\n",
        "        self.indices = indices\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.dataset[self.indices[idx]]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getattr__(self, name):\n",
        "        # This is the magic part:\n",
        "        # If the code asks for 'meta', 'fps', etc., and this class doesn't have it,\n",
        "        # it automatically looks inside the original dataset.\n",
        "        return getattr(self.dataset, name)\n",
        "\n",
        "# --- USAGE ---\n",
        "# Use SmartSubset instead of torch.utils.data.Subset\n",
        "debug_subset = SmartSubset(dataset, range(0, 50))\n",
        "\n",
        "# Now create your loader normally\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    debug_subset,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    drop_last=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader"
      ],
      "metadata": {
        "id": "Uo889iJKc5e9",
        "outputId": "3986f6b4-03e4-413b-f29d-81c83a9b2d07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x78562ffd8da0>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "xQogtb_kvxe3"
      },
      "outputs": [],
      "source": [
        "dl_iter = iter(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import importlib\n",
        "\n",
        "# Polyfill 'imp' for Python 3.12 compatibility\n",
        "if \"imp\" not in sys.modules:\n",
        "    import types\n",
        "    imp = types.ModuleType(\"imp\")\n",
        "    imp.reload = importlib.reload\n",
        "    sys.modules[\"imp\"] = imp\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "hbmQt2kiVyvD"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_C7BpnKMnwV"
      },
      "source": [
        "# Call Subtask Processor\n",
        "Important track the index for loss mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "JUEIX0ygQk2_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5e030a98-71ac-41a8-856c-651da7f201db"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[20:28:10]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Loaded item with index \u001b[1;36m2\u001b[0m                                                  \u001b]8;id=988210;file:///content/XHUMAN/xhuman/datasets/xhuman_dataset.py\u001b\\\u001b[2mxhuman_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=12038;file:///content/XHUMAN/xhuman/datasets/xhuman_dataset.py#190\u001b\\\u001b[2m190\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:28:10] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Loaded item with index <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                                                  <a href=\"file:///content/XHUMAN/xhuman/datasets/xhuman_dataset.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">xhuman_dataset.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///content/XHUMAN/xhuman/datasets/xhuman_dataset.py#190\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">190</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Loaded item with index \u001b[1;36m40\u001b[0m                                                 \u001b]8;id=787352;file:///content/XHUMAN/xhuman/datasets/xhuman_dataset.py\u001b\\\u001b[2mxhuman_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=279786;file:///content/XHUMAN/xhuman/datasets/xhuman_dataset.py#190\u001b\\\u001b[2m190\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Loaded item with index <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>                                                 <a href=\"file:///content/XHUMAN/xhuman/datasets/xhuman_dataset.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">xhuman_dataset.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///content/XHUMAN/xhuman/datasets/xhuman_dataset.py#190\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">190</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "frames = next(dl_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoLwg8RXNpML",
        "outputId": "7f2b352c-c394-4de0-8fe2-e295d62c046f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['observation.images.left', 'observation.images.top', 'observation.images.right', 'action', 'observation.state', 'timestamp', 'frame_index', 'episode_index', 'index', 'task_index', 'general_task_index', 'action_is_pad', 'task', 'general_task', 'train_with_subtask'])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "frames.keys()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frames[\"subtask\"] = frames[\"task\"]"
      ],
      "metadata": {
        "id": "80BV5rPKZNqb"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "0Gil7f3GuXsr"
      },
      "outputs": [],
      "source": [
        "batch = preprocessor.subtask(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W84U6GvCoMaN",
        "outputId": "6bc5e459-31b8-401a-a457-efe4143cc171"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['action', 'next.reward', 'next.done', 'next.truncated', 'info', 'action_is_pad', 'task', 'index', 'task_index', 'episode_index', 'subtask', 'subtask_tokens', 'observation.images.left', 'observation.images.top', 'observation.images.right', 'observation.state', 'observation.language.tokens', 'observation.language.attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "batch.keys()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub, tokens  = batch[\"subtask_tokens\"], batch[\"observation.language.tokens\"]"
      ],
      "metadata": {
        "id": "YjUdCZ7YZwZd"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sublang = tokenize.batch_decode(sub,skip_special_tokens=True)\n",
        "sublang"
      ],
      "metadata": {
        "id": "XsZcfHgWZ_hM",
        "outputId": "d2760894-9273-4609-8d5f-79787bcb3614",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pick up the strawberry and put it in the basket',\n",
              " 'pick up the strawberry and put it in the basket']"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenslang = tokenize.batch_decode(tokens,skip_special_tokens=True)\n",
        "tokenslang\n"
      ],
      "metadata": {
        "id": "K_hQ97hfaKS_",
        "outputId": "4ead158b-3d80-47f1-cbef-5138cf9ed388",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Task: pick up the strawberry and put it in the basket. Subtask: ',\n",
              " 'Task: pick up the strawberry and put it in the basket. Subtask: ']"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0y4OGwkSaH8K"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBWR8gXIpUu7"
      },
      "source": [
        "# Test loss calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "KfhgiZPZRlr4"
      },
      "outputs": [],
      "source": [
        "tokens_id = \"observation.language.tokens\"\n",
        "mask_id = \"observation.language.attention_mask\"\n",
        "\n",
        "tokens, masks = batch[tokens_id], batch[mask_id]\n",
        "noise = None\n",
        "time = None\n",
        "# Processor should have a method to get the subtask tokenized\n",
        "# List of tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenize = AutoTokenizer.from_pretrained(\"google/paligemma-3b-pt-224\")\n",
        "stokens = tokenize.batch_decode(tokens)"
      ],
      "metadata": {
        "id": "5c-daFvCRd43"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TA5SM9JSo_V",
        "outputId": "aeeeb9d4-b9b9-4887-a5ba-c89d166793c7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>Task: pick up the strawberry and put it in the basket. Subtask: <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
              " '<bos>Task: pick up the strawberry and put it in the basket. Subtask: <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "aX6UZZ_zSNtQ"
      },
      "execution_count": 59,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}