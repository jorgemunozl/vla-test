{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jorgemunozl/vla-test/blob/main/tests/train_val_pi05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2rYYgB4v8ry"
      },
      "source": [
<<<<<<< HEAD
        "# Fourtheen Test\n",
        "\n",
        "Description: Test the C.E loss for the subtask implementation\n",
        "\n",
        "Creation: 24 January 2026\n",
        "\n",
        "Last Update: None\n",
        "\n",
        "Result: CUDA run out of memory, but it should works, let's test on Colab"
=======
        "# Eleven Test\n",
        "\n",
        "This test run the training using the same architecture that the scrip that we use for train seriosuly our models."
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
<<<<<<< HEAD
      "metadata": {},
=======
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wgo2DrQ1wF5C",
        "outputId": "a57f496f-6425-4733-f337-92a27512d1a6"
      },
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "1\n"
=======
            "Cloning into 'XHUMAN'...\n",
            "remote: Enumerating objects: 2084, done.\u001b[K\n",
            "remote: Counting objects: 100% (290/290), done.\u001b[K\n",
            "remote: Compressing objects: 100% (185/185), done.\u001b[K\n",
            "remote: Total 2084 (delta 185), reused 184 (delta 102), pack-reused 1794 (from 2)\u001b[K\n",
            "Receiving objects: 100% (2084/2084), 7.81 MiB | 8.89 MiB/s, done.\n",
            "Resolving deltas: 100% (1328/1328), done.\n"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
          ]
        }
      ],
      "source": [
<<<<<<< HEAD
        "import os\n",
        "\n",
        "# Set this BEFORE importing pytorch/tensorflow\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "import torch\n",
        "# Check if it worked (should return 1 if you selected a single GPU)\n",
        "print(torch.cuda.device_count()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd XHUMAN\n",
        "!uv pip install -e .[pi]"
=======
        "# Clone\n"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
<<<<<<< HEAD
=======
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFr64v0rwSM8",
        "outputId": "68f1d5df-e243-4449-9908-e78d4c1ae387"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/XHUMAN\n"
          ]
        }
      ],
      "source": [
        "%cd XHUMAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljAwUMsOwm9P",
        "outputId": "354f5caf-5deb-4bcd-e09e-9ec5d8697367"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m215 packages\u001b[0m \u001b[2min 1.15s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 811ms\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 0.39ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 0.81ms\u001b[0m\u001b[0m\n",
            " \u001b[33m~\u001b[39m \u001b[1mxhuman\u001b[0m\u001b[2m==0.1.0 (from file:///content/XHUMAN)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!uv pip install -e .[pi]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
        "id": "7zILqJ7Wv8rz"
      },
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "from contextlib import nullcontext\n",
        "from typing import Any\n",
        "\n",
=======
        "\n",
        "from contextlib import nullcontext\n",
        "from typing import Any\n",
        "\n",
        "import torch\n",
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
        "from accelerate import Accelerator\n",
        "from accelerate.utils import DistributedDataParallelKwargs\n",
        "from torch.optim import Optimizer\n",
        "\n",
        "from lerobot.configs import parser\n",
        "from lerobot.datasets.sampler import EpisodeAwareSampler\n",
        "from lerobot.datasets.utils import cycle\n",
        "from lerobot.optim.factory import make_optimizer_and_scheduler\n",
        "from lerobot.policies.pretrained import PreTrainedPolicy\n",
        "from lerobot.utils.logging_utils import AverageMeter, MetricsTracker\n",
        "from lerobot.utils.random_utils import set_seed\n",
        "from lerobot.utils.train_utils import load_training_state\n",
        "from lerobot.utils.utils import (\n",
        "    format_big_number,\n",
        "    has_method,\n",
        "    init_logging,\n",
        ")\n",
        "\n",
        "from xhuman.policies.factory import make_xhuman_policy, make_xhuman_pre_post_processors\n",
        "from xhuman.configs.train import TrainPipelineConfigXHUMAN\n",
        "from xhuman.datasets.factory import make_dataset_xhuman\n",
        "from xhuman.datasets.utils import split_train_eval_episodes\n",
        "from xhuman.logger import logger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYlyeGygv8r0"
      },
      "source": [
        "## Helper Functions\n",
        "\n",
        "These functions handle dataset loading and policy updates. They are designed to work with distributed training using HuggingFace Accelerate."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 3,
=======
      "execution_count": 5,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "metadata": {
        "id": "CVmBxC-hv8r1"
      },
      "outputs": [],
      "source": [
        "def load_dataset(cfg: TrainPipelineConfigXHUMAN, episodes: list[int], is_main_process: bool = True, accelerator: Accelerator | None = None):\n",
        "    \"\"\"\n",
        "    Load the dataset for training and evaluation.\n",
        "    \"\"\"\n",
        "    # Dataset loading synchronization: main process downloads first to avoid race conditions\n",
        "    cfg.dataset.episodes = episodes\n",
<<<<<<< HEAD
        "    cfg.dataset.train_with_subtasks = True\n",
=======
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
        "\n",
        "    if is_main_process:\n",
        "        logger.info(\"Creating dataset\")\n",
        "        dataset = make_dataset_xhuman(cfg)\n",
        "\n",
        "    accelerator.wait_for_everyone()\n",
        "\n",
        "    # Now all other processes can safely load the dataset\n",
        "    if not is_main_process:\n",
        "        dataset = make_dataset_xhuman(cfg)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 4,
=======
      "execution_count": null,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "metadata": {
        "id": "iAqOQ9BS-8Xw"
      },
      "outputs": [],
      "source": [
        "def update_policy(\n",
        "    train_metrics: MetricsTracker,\n",
<<<<<<< HEAD
        "    step: int,\n",
=======
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
        "    policy: PreTrainedPolicy,\n",
        "    batch: Any,\n",
        "    optimizer: Optimizer,\n",
        "    grad_clip_norm: float,\n",
        "    accelerator: Accelerator,\n",
        "    lr_scheduler=None,\n",
        "    lock=None,\n",
        ") -> tuple[MetricsTracker, dict]:\n",
        "    \"\"\"\n",
        "    Performs a single training step to update the policy's weights.\n",
        "\n",
        "    This function executes the forward and backward passes,\n",
        "    clips gradients, and steps the optimizer and\n",
        "    learning rate scheduler. Accelerator handles\n",
        "    mixed-precision training automatically.\n",
        "\n",
        "    Args:\n",
        "        train_metrics: A MetricsTracker instance to record training statistics.\n",
        "        policy: The policy model to be trained.\n",
        "        batch: A batch of training data.\n",
        "        optimizer: The optimizer used to update the policy's parameters.\n",
        "        grad_clip_norm: The maximum norm for gradient clipping.\n",
        "        accelerator: The Accelerator instance for distributed training and mixed precision.\n",
        "        lr_scheduler: An optional learning rate scheduler.\n",
        "        lock: An optional lock for thread-safe optimizer updates.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing:\n",
        "        - The updated MetricsTracker with new statistics for this step.\n",
        "        - A dictionary of outputs from the policy's forward pass, for logging purposes.\n",
        "    \"\"\"\n",
        "    policy.train()\n",
        "\n",
        "    # Let accelerator handle mixed precision\n",
        "    with accelerator.autocast():\n",
<<<<<<< HEAD
        "        if step % 3 == 0:\n",
        "            loss, output_dict = policy.forward_subtask(batch)\n",
        "        else:\n",
        "            loss, output_dict = policy.forward(batch)\n",
=======
        "        loss, dict_loss = policy.forward_subtask(batch)\n",
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
        "\n",
        "    # Use accelerator's backward method\n",
        "    accelerator.backward(loss)\n",
        "\n",
        "    # Clip gradients if specified\n",
        "    if grad_clip_norm > 0:\n",
        "        grad_norm = accelerator.clip_grad_norm_(policy.parameters(), grad_clip_norm)\n",
        "    else:\n",
        "        grad_norm = torch.nn.utils.clip_grad_norm_(\n",
        "            policy.parameters(), float(\"inf\"), error_if_nonfinite=False\n",
        "        )\n",
        "\n",
        "    # Optimizer step\n",
        "    with lock if lock is not None else nullcontext():\n",
        "        optimizer.step()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Step through pytorch scheduler at every batch instead of epoch\n",
        "    if lr_scheduler is not None:\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    # Update internal buffers if policy has update method\n",
        "    if has_method(accelerator.unwrap_model(policy, keep_fp32_wrapper=True), \"update\"):\n",
        "        accelerator.unwrap_model(policy, keep_fp32_wrapper=True).update()\n",
        "\n",
        "    # Track losses for logging\n",
        "    # total_loss is per-sample [B], so we track the mean\n",
        "    train_metrics.loss = loss.item()\n",
        "    train_metrics.grad_norm = grad_norm.item()\n",
        "    train_metrics.lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "    # Create output dictionary with tracked losses\n",
        "    output_dict = {\n",
        "        \"loss\": loss.mean().item(),\n",
        "    }\n",
        "\n",
        "    return train_metrics, output_dict"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 5,
=======
      "execution_count": null,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "metadata": {
        "id": "lK93NSNOuXsi"
      },
      "outputs": [],
      "source": [
        "from xhuman.policies.pi05ki.configuration_pi05ki import PI05KIConfig\n",
        "\n",
        "policy_config = PI05KIConfig(repo_id=\"none\",device=\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipXWi5oev8r2"
      },
      "source": [
        "## Configuration and Setup\n",
        "\n",
        "Configure your dataset and policy settings here. The dataset configuration specifies which HuggingFace repository to load, and the policy configuration sets up the PI05 model architecture."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 6,
=======
      "execution_count": null,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "metadata": {
        "id": "XEbEEWDbzMPT"
      },
      "outputs": [],
      "source": [
        "from xhuman.configs.default import LerobotDatasetConfig\n",
        "\n",
        "dataset_config = LerobotDatasetConfig(\n",
        "    repo_id=\"NONHUMAN-RESEARCH/test-general-idx\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 7,
=======
      "execution_count": 10,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "metadata": {
        "id": "IZ1d9a3Ov8r3"
      },
      "outputs": [],
      "source": [
        "cfg = TrainPipelineConfigXHUMAN(\n",
        "    dataset=dataset_config,\n",
        "    policy=policy_config # Example policy configuration, replace with your actual policy path\n",
        ")\n",
        "cfg.validate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgSIm33Qv8r3"
      },
      "source": [
        "## Training Setup\n",
        "\n",
        "Initialize the Accelerator for distributed training and set up the training environment. The accelerator automatically handles:\n",
        "- Multi-GPU training\n",
        "- Mixed precision training\n",
        "- Gradient synchronization across processes"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 8,
=======
      "execution_count": 11,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "metadata": {
        "id": "XOJhp41Sv8r4"
      },
      "outputs": [],
      "source": [
        "# Create Accelerator\n",
        "# It will automatically detect if running in distributed mode or single-process mode\n",
        "# We set step_scheduler_with_optimizer=False to prevent accelerate from adjusting the lr_scheduler steps based on the num_processes\n",
        "# We set find_unused_parameters=True to handle models with conditional computation\n",
        "ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)\n",
        "accelerator = Accelerator(step_scheduler_with_optimizer=False, kwargs_handlers=[ddp_kwargs])\n",
        "\n",
        "init_logging(accelerator=accelerator)\n",
        "\n",
        "# Determine if this is the main process (for logging and checkpointing)\n",
        "is_main_process = accelerator.is_main_process\n",
        "\n",
        "# Set seed if specified\n",
        "if cfg.seed is not None:\n",
        "    set_seed(cfg.seed, accelerator=accelerator)\n",
        "\n",
        "# Use accelerator's device\n",
        "device = accelerator.device\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cuda.matmul.allow_tf32 = True"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 9,
=======
      "execution_count": null,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "s_gB_Dpbv8r5",
        "outputId": "295de906-d49f-41c8-f458-1dd065450bde"
      },
      "outputs": [
        {
<<<<<<< HEAD
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to read file '/home/lperez/.cache/huggingface/lerobot/NONHUMAN-RESEARCH/test-general-idx/data/chunk-000/file-000.parquet' with error <class 'datasets.table.CastError'>: Couldn't cast\n",
            "action: list<element: float>\n",
            "  child 0, element: float\n",
            "observation.state: list<element: float>\n",
            "  child 0, element: float\n",
            "timestamp: float\n",
            "frame_index: int64\n",
            "episode_index: int64\n",
            "index: int64\n",
            "task_index: int64\n",
            "general_task_index: int64\n",
            "-- schema metadata --\n",
            "pandas: '{\"index_columns\": [], \"column_indexes\": [], \"columns\": [{\"name\":' + 1051\n",
            "to\n",
            "{'action': List(Value('float32'), length=14), 'observation.state': List(Value('float32'), length=14), 'timestamp': Value('float32'), 'frame_index': Value('int64'), 'episode_index': Value('int64'), 'index': Value('int64'), 'task_index': Value('int64')}\n",
            "because column names don't match\n",
            "ERROR 2026-01-27 11:02:15 /parquet.py:108 Failed to read file '/home/lperez/.cache/huggingface/lerobot/NONHUMAN-RESEARCH/test-general-idx/data/chunk-000/file-000.parquet' with error <class 'datasets.table.CastError'>: Couldn't cast\n",
            "action: list<element: float>\n",
            "  child 0, element: float\n",
            "observation.state: list<element: float>\n",
            "  child 0, element: float\n",
            "timestamp: float\n",
            "frame_index: int64\n",
            "episode_index: int64\n",
            "index: int64\n",
            "task_index: int64\n",
            "general_task_index: int64\n",
            "-- schema metadata --\n",
            "pandas: '{\"index_columns\": [], \"column_indexes\": [], \"columns\": [{\"name\":' + 1051\n",
            "to\n",
            "{'action': List(Value('float32'), length=14), 'observation.state': List(Value('float32'), length=14), 'timestamp': Value('float32'), 'frame_index': Value('int64'), 'episode_index': Value('int64'), 'index': Value('int64'), 'task_index': Value('int64')}\n",
            "because column names don't match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Dataset loading failed with strict features (DatasetGenerationError). Retrying without features constraint.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11:02:15] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Total episodes available: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">437</span>                                                  <a href=\"file:///tmp/ipykernel_2576943/3893944116.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3893944116.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_2576943/3893944116.py#16\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[11:02:15]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Total episodes available: \u001b[1;36m437\u001b[0m                                                  \u001b]8;id=370116;file:///tmp/ipykernel_2576943/3893944116.py\u001b\\\u001b[2m3893944116.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=65997;file:///tmp/ipykernel_2576943/3893944116.py#16\u001b\\\u001b[2m16\u001b[0m\u001b]8;;\u001b\\\n"
=======
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:12:47] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Total episodes available: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>                                     <a href=\"file:///tmp/ipython-input-1033998473.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-1033998473.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-1033998473.py#16\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[15:12:47]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Total episodes available: \u001b[1;36m11\u001b[0m                                     \u001b]8;id=370116;file:///tmp/ipython-input-1033998473.py\u001b\\\u001b[2mipython-input-1033998473.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=65997;file:///tmp/ipython-input-1033998473.py#16\u001b\\\u001b[2m16\u001b[0m\u001b]8;;\u001b\\\n"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
<<<<<<< HEAD
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> DEBUG MODE: Using only <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span> episodes                                            <a href=\"file:///tmp/ipykernel_2576943/3893944116.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3893944116.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_2576943/3893944116.py#28\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m DEBUG MODE: Using only \u001b[1;36m200\u001b[0m episodes                                            \u001b]8;id=232594;file:///tmp/ipykernel_2576943/3893944116.py\u001b\\\u001b[2m3893944116.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=703849;file:///tmp/ipykernel_2576943/3893944116.py#28\u001b\\\u001b[2m28\u001b[0m\u001b]8;;\u001b\\\n"
=======
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> DEBUG MODE: Using only <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> episodes                                <a href=\"file:///tmp/ipython-input-1033998473.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-1033998473.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-1033998473.py#28\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m DEBUG MODE: Using only \u001b[1;36m3\u001b[0m episodes                                \u001b]8;id=232594;file:///tmp/ipython-input-1033998473.py\u001b\\\u001b[2mipython-input-1033998473.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=703849;file:///tmp/ipython-input-1033998473.py#28\u001b\\\u001b[2m28\u001b[0m\u001b]8;;\u001b\\\n"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
<<<<<<< HEAD
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Loading train dataset with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">160</span> episodes                                        <a href=\"file:///tmp/ipykernel_2576943/3893944116.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3893944116.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_2576943/3893944116.py#40\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">40</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Loading train dataset with \u001b[1;36m160\u001b[0m episodes                                        \u001b]8;id=723378;file:///tmp/ipykernel_2576943/3893944116.py\u001b\\\u001b[2m3893944116.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=210922;file:///tmp/ipykernel_2576943/3893944116.py#40\u001b\\\u001b[2m40\u001b[0m\u001b]8;;\u001b\\\n"
=======
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Loading train dataset with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> episodes                            <a href=\"file:///tmp/ipython-input-1033998473.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-1033998473.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-1033998473.py#40\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">40</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Loading train dataset with \u001b[1;36m2\u001b[0m episodes                            \u001b]8;id=146316;file:///tmp/ipython-input-1033998473.py\u001b\\\u001b[2mipython-input-1033998473.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=772246;file:///tmp/ipython-input-1033998473.py#40\u001b\\\u001b[2m40\u001b[0m\u001b]8;;\u001b\\\n"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
<<<<<<< HEAD
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Creating dataset                                                               <a href=\"file:///tmp/ipykernel_2576943/3578173160.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3578173160.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_2576943/3578173160.py#10\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Creating dataset                                                               \u001b]8;id=459381;file:///tmp/ipykernel_2576943/3578173160.py\u001b\\\u001b[2m3578173160.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=943313;file:///tmp/ipykernel_2576943/3578173160.py#10\u001b\\\u001b[2m10\u001b[0m\u001b]8;;\u001b\\\n"
=======
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Creating dataset                                                  <a href=\"file:///tmp/ipython-input-1989669429.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-1989669429.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-1989669429.py#9\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">9</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Creating dataset                                                  \u001b]8;id=619176;file:///tmp/ipython-input-1989669429.py\u001b\\\u001b[2mipython-input-1989669429.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=442417;file:///tmp/ipython-input-1989669429.py#9\u001b\\\u001b[2m9\u001b[0m\u001b]8;;\u001b\\\n"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
            ]
          },
          "metadata": {},
          "output_type": "display_data"
<<<<<<< HEAD
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Dataset loading failed with strict features (ValueError). Retrying without features constraint.\n"
          ]
=======
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# Dataset Loading with Episode Filtering\n",
        "# ============================================================================\n",
        "# This cell loads the dataset with proper episode filtering.\n",
        "# For debugging: Set DEBUG_MODE = True to use only a subset of episodes\n",
        "# For production: Set DEBUG_MODE = False to use all available episodes\n",
        "\n",
        "DEBUG_MODE = True  # Set to False for full training\n",
<<<<<<< HEAD
        "DEBUG_MAX_EPISODES = 200  # Use only first N episodes for debugging\n",
=======
        "DEBUG_MAX_EPISODES = 3  # Use only first N episodes for debugging\n",
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
        "\n",
        "# First, get total episodes count (load minimal dataset to check)\n",
        "if is_main_process:\n",
        "    temp_dataset = make_dataset_xhuman(cfg)\n",
        "    total_episodes = temp_dataset.meta.total_episodes\n",
        "    del temp_dataset\n",
        "    logger.info(f\"Total episodes available: {total_episodes}\")\n",
        "else:\n",
        "    # For non-main processes, use a reasonable default\n",
        "    # In practice, this will be synced after main process loads\n",
        "    total_episodes = 4  # Fallback - adjust if needed\n",
        "\n",
        "accelerator.wait_for_everyone()\n",
        "\n",
        "# Limit episodes for debugging\n",
        "if DEBUG_MODE:\n",
        "    episodes = list(range(min(DEBUG_MAX_EPISODES, total_episodes)))\n",
        "    if is_main_process:\n",
        "        logger.info(f\"DEBUG MODE: Using only {len(episodes)} episodes\")\n",
        "else:\n",
        "    episodes = list(range(total_episodes))\n",
        "\n",
        "# Split episodes\n",
        "train_episodes, eval_episodes = split_train_eval_episodes(\n",
        "    episodes, split_ratio=cfg.split_ratio, seed=42\n",
        ")\n",
        "\n",
        "# Load dataset with ONLY train episodes (proper way to filter)\n",
        "# This uses the load_dataset helper function which sets cfg.dataset.episodes\n",
        "if is_main_process:\n",
        "    logger.info(f\"Loading train dataset with {len(train_episodes)} episodes\")\n",
        "dataset = load_dataset(cfg, train_episodes, is_main_process=is_main_process, accelerator=accelerator)\n",
        "dataset.train_with_subtask = True"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 10,
=======
      "execution_count": 13,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "L2T_kvevv8r6",
        "outputId": "8aaa9681-4499-4985-c0a6-6ae97878351c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
<<<<<<< HEAD
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11:02:19] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Creating policy                                                                 <a href=\"file:///tmp/ipykernel_2576943/3499831122.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3499831122.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_2576943/3499831122.py#3\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[11:02:19]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Creating policy                                                                 \u001b]8;id=354508;file:///tmp/ipykernel_2576943/3499831122.py\u001b\\\u001b[2m3499831122.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=22056;file:///tmp/ipykernel_2576943/3499831122.py#3\u001b\\\u001b[2m3\u001b[0m\u001b]8;;\u001b\\\n"
=======
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:12:50] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Creating policy                                                   <a href=\"file:///tmp/ipython-input-3499831122.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-3499831122.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-3499831122.py#3\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[15:12:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Creating policy                                                   \u001b]8;id=631262;file:///tmp/ipython-input-3499831122.py\u001b\\\u001b[2mipython-input-3499831122.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=27824;file:///tmp/ipython-input-3499831122.py#3\u001b\\\u001b[2m3\u001b[0m\u001b]8;;\u001b\\\n"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
            ]
          },
          "metadata": {},
          "output_type": "display_data"
<<<<<<< HEAD
=======
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n"
          ]
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
        }
      ],
      "source": [
        "# Create policy\n",
        "if is_main_process:\n",
        "    logger.info(\"Creating policy\")\n",
        "policy = make_xhuman_policy(\n",
        "    cfg=cfg.policy,\n",
        "    ds_meta=dataset.meta,\n",
        ")\n",
        "\n",
        "accelerator.wait_for_everyone()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WeVjdudv8r6"
      },
      "source": [
        "## Dataset and Model Information\n",
        "\n",
        "Display metadata about the loaded dataset and model. This includes:\n",
        "- Total number of episodes and frames\n",
        "- Model parameter counts\n",
        "- Effective batch size (accounting for distributed training)"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 11,
=======
      "execution_count": 14,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4cFEE9pv8r6",
        "outputId": "846663c9-d50d-460f-ece2-78627fa04e86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "DATASET METADATA\n",
            "================================================================================\n",
            "\n",
<<<<<<< HEAD
            "Dataset Repository: NONHUMAN-RESEARCH/test-general-idx\n",
            "Total Episodes: 437\n",
            "Training Episodes: 160\n",
            "Number of Frames: 151,548\n",
            "Number of Episodes (loaded): 160\n",
=======
            "Dataset Repository: NONHUMAN-RESEARCH/pick-and-place-fruits-v2-test\n",
            "Total Episodes: 11\n",
            "Training Episodes: 2\n",
            "Number of Frames: 2,924\n",
            "Number of Episodes (loaded): 2\n",
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Display dataset metadata and model configuration\n",
        "if is_main_process:\n",
        "    from pprint import pprint\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"DATASET METADATA\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"\\nDataset Repository: {dataset.repo_id}\")\n",
        "    print(f\"Total Episodes: {dataset.meta.total_episodes}\")\n",
        "    print(f\"Training Episodes: {len(train_episodes)}\")\n",
        "    print(f\"Number of Frames: {dataset.num_frames:,}\")\n",
        "    print(f\"Number of Episodes (loaded): {dataset.num_episodes}\")\n",
        "\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 12,
=======
      "execution_count": 15,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "metadata": {
        "id": "ADIBf_oF0T0_"
      },
      "outputs": [],
      "source": [
        "processor_kwargs = {}\n",
        "postprocessor_kwargs = {}\n",
        "\n",
        "if (cfg.policy.pretrained_path and not cfg.resume) or not cfg.policy.pretrained_path:\n",
        "    processor_kwargs[\"dataset_stats\"] = dataset.meta.stats\n",
        "\n",
        "if cfg.policy.pretrained_path is not None:\n",
        "    processor_kwargs[\"preprocessor_overrides\"] = {\n",
        "        \"device_processor\": {\"device\": device.type},\n",
        "        \"normalizer_processor\": {\n",
        "            \"stats\": dataset.meta.stats,\n",
        "            \"features\": {**policy.config.input_features, **policy.config.output_features},\n",
        "            \"norm_map\": policy.config.normalization_mapping,\n",
        "        },\n",
        "    }\n",
        "    postprocessor_kwargs[\"postprocessor_overrides\"] = {\n",
        "        \"unnormalizer_processor\": {\n",
        "            \"stats\": dataset.meta.stats,\n",
        "            \"features\": policy.config.output_features,\n",
        "            \"norm_map\": policy.config.normalization_mapping,\n",
        "        },\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 13,
=======
      "execution_count": null,
      "metadata": {
        "id": "suwirY3L1HHQ"
      },
      "outputs": [],
      "source": [
        "# This cell was removed - autoreload is not needed for production training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "metadata": {
        "id": "rcEUR_P1v8r7"
      },
      "outputs": [],
      "source": [
        "# Create processors\n",
        "preprocessor, postprocessor = make_xhuman_pre_post_processors(\n",
        "    policy_cfg=cfg.policy,\n",
        "    pretrained_path=cfg.policy.pretrained_path,\n",
        "    **processor_kwargs,\n",
        "    **postprocessor_kwargs,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 14,
=======
      "execution_count": 17,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Zj87lmHcv8r7",
        "outputId": "5641eaeb-1a99-48d9-fa41-98e1157775c0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
<<<<<<< HEAD
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11:02:58] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Creating optimizer and scheduler                                                <a href=\"file:///tmp/ipykernel_2576943/1795964688.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1795964688.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_2576943/1795964688.py#3\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[11:02:58]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Creating optimizer and scheduler                                                \u001b]8;id=74441;file:///tmp/ipykernel_2576943/1795964688.py\u001b\\\u001b[2m1795964688.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=742225;file:///tmp/ipykernel_2576943/1795964688.py#3\u001b\\\u001b[2m3\u001b[0m\u001b]8;;\u001b\\\n"
=======
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:14:10] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Creating optimizer and scheduler                                  <a href=\"file:///tmp/ipython-input-1795964688.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-1795964688.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-1795964688.py#3\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[15:14:10]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Creating optimizer and scheduler                                  \u001b]8;id=439898;file:///tmp/ipython-input-1795964688.py\u001b\\\u001b[2mipython-input-1795964688.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=231148;file:///tmp/ipython-input-1795964688.py#3\u001b\\\u001b[2m3\u001b[0m\u001b]8;;\u001b\\\n"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create optimizer and scheduler\n",
        "if is_main_process:\n",
        "    logger.info(\"Creating optimizer and scheduler\")\n",
        "optimizer, lr_scheduler = make_optimizer_and_scheduler(cfg, policy)\n",
        "\n",
        "step = 0  # number of policy updates\n",
        "\n",
        "# Resume from checkpoint if needed\n",
        "if cfg.resume:\n",
        "    step, optimizer, lr_scheduler = load_training_state(cfg.checkpoint_path, optimizer, lr_scheduler)"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 15,
=======
      "execution_count": 18,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "E_d1t5DWv8r8",
        "outputId": "0c7d5f85-138d-4cf1-ae28-99b1bfc410da"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
<<<<<<< HEAD
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Output dir: outputs/train/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2026</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-14_pi05_ki                           <a href=\"file:///tmp/ipykernel_2576943/4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_2576943/4288334519.py#5\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Output dir: outputs/train/\u001b[1;36m2026\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m27\u001b[0m/\u001b[1;36m11\u001b[0m-\u001b[1;36m02\u001b[0m-14_pi05_ki                           \u001b]8;id=901393;file:///tmp/ipykernel_2576943/4288334519.py\u001b\\\u001b[2m4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=346479;file:///tmp/ipykernel_2576943/4288334519.py#5\u001b\\\u001b[2m5\u001b[0m\u001b]8;;\u001b\\\n"
=======
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Output dir: outputs/train/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2026</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-44_pi05_ki             <a href=\"file:///tmp/ipython-input-4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-4288334519.py#5\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Output dir: outputs/train/\u001b[1;36m2026\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m14\u001b[0m/\u001b[1;36m15\u001b[0m-\u001b[1;36m12\u001b[0m-44_pi05_ki             \u001b]8;id=795667;file:///tmp/ipython-input-4288334519.py\u001b\\\u001b[2mipython-input-4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=844962;file:///tmp/ipython-input-4288334519.py#5\u001b\\\u001b[2m5\u001b[0m\u001b]8;;\u001b\\\n"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
<<<<<<< HEAD
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Steps: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100000</span> <span style=\"font-weight: bold\">(</span>100K<span style=\"font-weight: bold\">)</span>                                                            <a href=\"file:///tmp/ipykernel_2576943/4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_2576943/4288334519.py#6\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Steps: \u001b[1;36m100000\u001b[0m \u001b[1m(\u001b[0m100K\u001b[1m)\u001b[0m                                                            \u001b]8;id=508993;file:///tmp/ipykernel_2576943/4288334519.py\u001b\\\u001b[2m4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=224643;file:///tmp/ipykernel_2576943/4288334519.py#6\u001b\\\u001b[2m6\u001b[0m\u001b]8;;\u001b\\\n"
=======
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Steps: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100000</span> <span style=\"font-weight: bold\">(</span>100K<span style=\"font-weight: bold\">)</span>                                              <a href=\"file:///tmp/ipython-input-4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-4288334519.py#6\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Steps: \u001b[1;36m100000\u001b[0m \u001b[1m(\u001b[0m100K\u001b[1m)\u001b[0m                                              \u001b]8;id=163032;file:///tmp/ipython-input-4288334519.py\u001b\\\u001b[2mipython-input-4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=225772;file:///tmp/ipython-input-4288334519.py#6\u001b\\\u001b[2m6\u001b[0m\u001b]8;;\u001b\\\n"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
<<<<<<< HEAD
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Dataset frames: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">151548</span> <span style=\"font-weight: bold\">(</span>152K<span style=\"font-weight: bold\">)</span>                                                   <a href=\"file:///tmp/ipykernel_2576943/4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_2576943/4288334519.py#7\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">7</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Dataset frames: \u001b[1;36m151548\u001b[0m \u001b[1m(\u001b[0m152K\u001b[1m)\u001b[0m                                                   \u001b]8;id=598782;file:///tmp/ipykernel_2576943/4288334519.py\u001b\\\u001b[2m4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=604201;file:///tmp/ipykernel_2576943/4288334519.py#7\u001b\\\u001b[2m7\u001b[0m\u001b]8;;\u001b\\\n"
=======
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Dataset frames: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2924</span> <span style=\"font-weight: bold\">(</span>3K<span style=\"font-weight: bold\">)</span>                                         <a href=\"file:///tmp/ipython-input-4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-4288334519.py#7\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">7</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Dataset frames: \u001b[1;36m2924\u001b[0m \u001b[1m(\u001b[0m3K\u001b[1m)\u001b[0m                                         \u001b]8;id=101414;file:///tmp/ipython-input-4288334519.py\u001b\\\u001b[2mipython-input-4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=376417;file:///tmp/ipython-input-4288334519.py#7\u001b\\\u001b[2m7\u001b[0m\u001b]8;;\u001b\\\n"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
<<<<<<< HEAD
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Dataset episodes: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">160</span>                                                           <a href=\"file:///tmp/ipykernel_2576943/4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_2576943/4288334519.py#8\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Dataset episodes: \u001b[1;36m160\u001b[0m                                                           \u001b]8;id=426833;file:///tmp/ipykernel_2576943/4288334519.py\u001b\\\u001b[2m4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=199659;file:///tmp/ipykernel_2576943/4288334519.py#8\u001b\\\u001b[2m8\u001b[0m\u001b]8;;\u001b\\\n"
=======
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Dataset episodes: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                                               <a href=\"file:///tmp/ipython-input-4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-4288334519.py#8\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Dataset episodes: \u001b[1;36m2\u001b[0m                                               \u001b]8;id=45561;file:///tmp/ipython-input-4288334519.py\u001b\\\u001b[2mipython-input-4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=765179;file:///tmp/ipython-input-4288334519.py#8\u001b\\\u001b[2m8\u001b[0m\u001b]8;;\u001b\\\n"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
<<<<<<< HEAD
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Effective batch size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> x <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>                                                <a href=\"file:///tmp/ipykernel_2576943/4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_2576943/4288334519.py#11\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Effective batch size: \u001b[1;36m8\u001b[0m x \u001b[1;36m1\u001b[0m = \u001b[1;36m8\u001b[0m                                                \u001b]8;id=444154;file:///tmp/ipykernel_2576943/4288334519.py\u001b\\\u001b[2m4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=431071;file:///tmp/ipykernel_2576943/4288334519.py#11\u001b\\\u001b[2m11\u001b[0m\u001b]8;;\u001b\\\n"
=======
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Effective batch size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> x <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>                                  <a href=\"file:///tmp/ipython-input-4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-4288334519.py#11\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Effective batch size: \u001b[1;36m8\u001b[0m x \u001b[1;36m1\u001b[0m = \u001b[1;36m8\u001b[0m                                  \u001b]8;id=82627;file:///tmp/ipython-input-4288334519.py\u001b\\\u001b[2mipython-input-4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=578856;file:///tmp/ipython-input-4288334519.py#11\u001b\\\u001b[2m11\u001b[0m\u001b]8;;\u001b\\\n"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
<<<<<<< HEAD
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Learnable params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3616757520</span> <span style=\"font-weight: bold\">(</span>4B<span style=\"font-weight: bold\">)</span>                                              <a href=\"file:///tmp/ipykernel_2576943/4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_2576943/4288334519.py#12\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Learnable params: \u001b[1;36m3616757520\u001b[0m \u001b[1m(\u001b[0m4B\u001b[1m)\u001b[0m                                              \u001b]8;id=685197;file:///tmp/ipykernel_2576943/4288334519.py\u001b\\\u001b[2m4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=677568;file:///tmp/ipykernel_2576943/4288334519.py#12\u001b\\\u001b[2m12\u001b[0m\u001b]8;;\u001b\\\n"
=======
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Learnable params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3616757520</span> <span style=\"font-weight: bold\">(</span>4B<span style=\"font-weight: bold\">)</span>                                <a href=\"file:///tmp/ipython-input-4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-4288334519.py#12\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Learnable params: \u001b[1;36m3616757520\u001b[0m \u001b[1m(\u001b[0m4B\u001b[1m)\u001b[0m                                \u001b]8;id=903565;file:///tmp/ipython-input-4288334519.py\u001b\\\u001b[2mipython-input-4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=379201;file:///tmp/ipython-input-4288334519.py#12\u001b\\\u001b[2m12\u001b[0m\u001b]8;;\u001b\\\n"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
<<<<<<< HEAD
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Total params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3616757520</span> <span style=\"font-weight: bold\">(</span>4B<span style=\"font-weight: bold\">)</span>                                                  <a href=\"file:///tmp/ipykernel_2576943/4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_2576943/4288334519.py#13\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Total params: \u001b[1;36m3616757520\u001b[0m \u001b[1m(\u001b[0m4B\u001b[1m)\u001b[0m                                                  \u001b]8;id=839482;file:///tmp/ipykernel_2576943/4288334519.py\u001b\\\u001b[2m4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=903529;file:///tmp/ipykernel_2576943/4288334519.py#13\u001b\\\u001b[2m13\u001b[0m\u001b]8;;\u001b\\\n"
=======
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Total params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3616757520</span> <span style=\"font-weight: bold\">(</span>4B<span style=\"font-weight: bold\">)</span>                                    <a href=\"file:///tmp/ipython-input-4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-4288334519.py#13\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Total params: \u001b[1;36m3616757520\u001b[0m \u001b[1m(\u001b[0m4B\u001b[1m)\u001b[0m                                    \u001b]8;id=693384;file:///tmp/ipython-input-4288334519.py\u001b\\\u001b[2mipython-input-4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=238968;file:///tmp/ipython-input-4288334519.py#13\u001b\\\u001b[2m13\u001b[0m\u001b]8;;\u001b\\\n"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Print training info\n",
        "if is_main_process:\n",
        "    num_learnable_params = sum(p.numel() for p in policy.parameters() if p.requires_grad)\n",
        "    num_total_params = sum(p.numel() for p in policy.parameters())\n",
        "    logger.info(f\"Output dir: {cfg.output_dir}\")\n",
        "    logger.info(f\"Steps: {cfg.steps} ({format_big_number(cfg.steps)})\")\n",
        "    logger.info(f\"Dataset frames: {dataset.num_frames} ({format_big_number(dataset.num_frames)})\")\n",
        "    logger.info(f\"Dataset episodes: {dataset.num_episodes}\")\n",
        "    num_processes = accelerator.num_processes\n",
        "    effective_bs = cfg.batch_size * num_processes\n",
        "    logger.info(f\"Effective batch size: {cfg.batch_size} x {num_processes} = {effective_bs}\")\n",
        "    logger.info(f\"Learnable params: {num_learnable_params} ({format_big_number(num_learnable_params)})\")\n",
        "    logger.info(f\"Total params: {num_total_params} ({format_big_number(num_total_params)})\")"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 16,
=======
      "execution_count": 19,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "jAOHZFNwv8r8",
        "outputId": "417243eb-a1d9-4a54-a882-a2cf21c6480f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
<<<<<<< HEAD
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Not dropping any frames                                                        <a href=\"file:///tmp/ipykernel_2576943/4111286182.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4111286182.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_2576943/4111286182.py#12\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Not dropping any frames                                                        \u001b]8;id=146991;file:///tmp/ipykernel_2576943/4111286182.py\u001b\\\u001b[2m4111286182.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=442374;file:///tmp/ipykernel_2576943/4111286182.py#12\u001b\\\u001b[2m12\u001b[0m\u001b]8;;\u001b\\\n"
=======
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:14:11] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Not dropping any frames                                          <a href=\"file:///tmp/ipython-input-4111286182.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-4111286182.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-4111286182.py#12\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[15:14:11]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Not dropping any frames                                          \u001b]8;id=105907;file:///tmp/ipython-input-4111286182.py\u001b\\\u001b[2mipython-input-4111286182.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=398591;file:///tmp/ipython-input-4111286182.py#12\u001b\\\u001b[2m12\u001b[0m\u001b]8;;\u001b\\\n"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create dataloader\n",
        "if hasattr(cfg.policy, \"drop_n_last_frames\"):\n",
        "    logger.info(f\"Dropping {cfg.policy.drop_n_last_frames} last frames\")\n",
        "    shuffle = False\n",
        "    sampler = EpisodeAwareSampler(\n",
        "        dataset.meta.episodes[\"dataset_from_index\"],\n",
        "        dataset.meta.episodes[\"dataset_to_index\"],\n",
        "        drop_n_last_frames=cfg.policy.drop_n_last_frames,\n",
        "        shuffle=True,\n",
        "    )\n",
        "else:\n",
        "    logger.info(\"Not dropping any frames\")\n",
        "    shuffle = True\n",
        "    sampler = None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 17,
=======
      "execution_count": 20,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "metadata": {
        "id": "hSpoN-wy-8X3"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SmartSubset(Dataset):\n",
        "    def __init__(self, dataset, indices):\n",
        "        self.dataset = dataset\n",
        "        self.indices = indices\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.dataset[self.indices[idx]]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getattr__(self, name):\n",
        "        # This is the magic part:\n",
        "        # If the code asks for 'meta', 'fps', etc., and this class doesn't have it,\n",
        "        # it automatically looks inside the original dataset.\n",
        "        return getattr(self.dataset, name)\n",
        "\n",
        "# --- USAGE ---\n",
        "# Use SmartSubset instead of torch.utils.data.Subset\n",
        "debug_subset = SmartSubset(dataset, range(0, 50))\n",
        "\n",
        "# Now create your loader normally\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    debug_subset,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    drop_last=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 18,
=======
      "execution_count": 21,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "metadata": {
        "id": "uMGOkAcg-8X4"
      },
      "outputs": [],
      "source": [
        "# Prepare everything with accelerator\n",
        "accelerator.wait_for_everyone()\n",
        "policy, optimizer, dataloader, lr_scheduler = accelerator.prepare(\n",
        "    policy, optimizer, train_dataloader, lr_scheduler\n",
        ")\n",
        "\n",
        "policy.train()\n",
        "\n",
        "# Setup metrics tracking\n",
        "train_metrics = {\n",
        "    \"loss\": AverageMeter(\"loss\", \":.3f\"),\n",
        "    \"grad_norm\": AverageMeter(\"grdn\", \":.3f\"),\n",
        "    \"lr\": AverageMeter(\"lr\", \":0.1e\"),\n",
        "    \"update_s\": AverageMeter(\"updt_s\", \":.3f\"),\n",
        "    \"dataloading_s\": AverageMeter(\"data_s\", \":.3f\"),\n",
        "}\n",
        "\n",
        "effective_batch_size = cfg.batch_size * accelerator.num_processes"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 19,
=======
      "execution_count": 22,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "metadata": {
        "id": "JZKSXs7r-8X4"
      },
      "outputs": [],
      "source": [
        "train_tracker = MetricsTracker(\n",
        "    effective_batch_size,\n",
        "    dataset.num_frames,\n",
        "    dataset.num_episodes,\n",
        "    train_metrics,\n",
        "    initial_step=step,\n",
        "    accelerator=accelerator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 20,
=======
      "execution_count": 23,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "cF1NkqcTobVj",
        "outputId": "a4de313e-7628-4893-fe82-d762d0df3542"
      },
      "outputs": [
        {
          "data": {
<<<<<<< HEAD
=======
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
            "text/plain": [
              "'\\ndataloader = torch.utils.data.DataLoader(\\n    dataset,\\n    num_workers=cfg.num_workers,\\n    batch_size=2,\\n    shuffle=shuffle and not cfg.dataset.streaming,\\n    sampler=sampler,\\n    pin_memory=device.type == \"cuda\",\\n    drop_last=False,\\n    prefetch_factor=2 if cfg.num_workers > 0 else None,\\n)\\n'"
            ]
          },
<<<<<<< HEAD
          "execution_count": 20,
=======
          "execution_count": 23,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    num_workers=cfg.num_workers,\n",
        "    batch_size=2,\n",
        "    shuffle=shuffle and not cfg.dataset.streaming,\n",
        "    sampler=sampler,\n",
        "    pin_memory=device.type == \"cuda\",\n",
        "    drop_last=False,\n",
        "    prefetch_factor=2 if cfg.num_workers > 0 else None,\n",
        ")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 21,
=======
      "execution_count": 24,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "n7wHY5Q_7EMt",
        "outputId": "34ca52f3-ea14-4457-d26f-cd490482c9b8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
<<<<<<< HEAD
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Start offline training on a fixed dataset                                       <a href=\"file:///tmp/ipykernel_2576943/2557974599.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2557974599.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_2576943/2557974599.py#4\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Start offline training on a fixed dataset                                       \u001b]8;id=79046;file:///tmp/ipykernel_2576943/2557974599.py\u001b\\\u001b[2m2557974599.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=464656;file:///tmp/ipykernel_2576943/2557974599.py#4\u001b\\\u001b[2m4\u001b[0m\u001b]8;;\u001b\\\n"
=======
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:14:18] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Start offline training on a fixed dataset                         <a href=\"file:///tmp/ipython-input-2557974599.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-2557974599.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-2557974599.py#4\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[15:14:18]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Start offline training on a fixed dataset                         \u001b]8;id=388162;file:///tmp/ipython-input-2557974599.py\u001b\\\u001b[2mipython-input-2557974599.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=372528;file:///tmp/ipython-input-2557974599.py#4\u001b\\\u001b[2m4\u001b[0m\u001b]8;;\u001b\\\n"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
<<<<<<< HEAD
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Train episodes: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">160</span>                                                             <a href=\"file:///tmp/ipykernel_2576943/2557974599.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2557974599.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_2576943/2557974599.py#5\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Train episodes: \u001b[1;36m160\u001b[0m                                                             \u001b]8;id=53045;file:///tmp/ipykernel_2576943/2557974599.py\u001b\\\u001b[2m2557974599.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=683823;file:///tmp/ipykernel_2576943/2557974599.py#5\u001b\\\u001b[2m5\u001b[0m\u001b]8;;\u001b\\\n"
=======
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Train episodes: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                                                 <a href=\"file:///tmp/ipython-input-2557974599.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-2557974599.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-2557974599.py#5\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Train episodes: \u001b[1;36m2\u001b[0m                                                 \u001b]8;id=716751;file:///tmp/ipython-input-2557974599.py\u001b\\\u001b[2mipython-input-2557974599.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=679514;file:///tmp/ipython-input-2557974599.py#5\u001b\\\u001b[2m5\u001b[0m\u001b]8;;\u001b\\\n"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
<<<<<<< HEAD
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Total training steps: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100000</span>                                                    <a href=\"file:///tmp/ipykernel_2576943/2557974599.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2557974599.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_2576943/2557974599.py#6\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Total training steps: \u001b[1;36m100000\u001b[0m                                                    \u001b]8;id=790170;file:///tmp/ipykernel_2576943/2557974599.py\u001b\\\u001b[2m2557974599.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=889921;file:///tmp/ipykernel_2576943/2557974599.py#6\u001b\\\u001b[2m6\u001b[0m\u001b]8;;\u001b\\\n"
=======
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Total training steps: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100000</span>                                      <a href=\"file:///tmp/ipython-input-2557974599.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-2557974599.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-2557974599.py#6\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Total training steps: \u001b[1;36m100000\u001b[0m                                      \u001b]8;id=764544;file:///tmp/ipython-input-2557974599.py\u001b\\\u001b[2mipython-input-2557974599.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256702;file:///tmp/ipython-input-2557974599.py#6\u001b\\\u001b[2m6\u001b[0m\u001b]8;;\u001b\\\n"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Training initialization\n",
        "# This logs the start of training and shows how many episodes will be used\n",
        "if is_main_process:\n",
        "    logger.info(\"Start offline training on a fixed dataset\")\n",
        "    logger.info(f\"Train episodes: {len(train_episodes)}\")\n",
        "    logger.info(f\"Total training steps: {cfg.steps}\")"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 22,
=======
      "execution_count": 25,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "metadata": {
        "id": "tj-vGUvo-8X5"
      },
      "outputs": [],
      "source": [
        "\n",
        "dl_iter = cycle(dataloader)"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Loaded item with index <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>                                                 <a href=\"file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">xhuman_dataset.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py#265\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Loaded item with index \u001b[1;36m30\u001b[0m                                                 \u001b]8;id=906651;file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py\u001b\\\u001b[2mxhuman_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=420521;file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py#265\u001b\\\u001b[2m265\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Loaded item with index <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>                                                  <a href=\"file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">xhuman_dataset.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py#265\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Loaded item with index \u001b[1;36m3\u001b[0m                                                  \u001b]8;id=2260;file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py\u001b\\\u001b[2mxhuman_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=409386;file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py#265\u001b\\\u001b[2m265\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Loaded item with index <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span>                                                 <a href=\"file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">xhuman_dataset.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py#265\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Loaded item with index \u001b[1;36m31\u001b[0m                                                 \u001b]8;id=477110;file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py\u001b\\\u001b[2mxhuman_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=299105;file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py#265\u001b\\\u001b[2m265\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Loaded item with index <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>                                                 <a href=\"file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">xhuman_dataset.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py#265\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Loaded item with index \u001b[1;36m33\u001b[0m                                                 \u001b]8;id=582765;file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py\u001b\\\u001b[2mxhuman_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=694022;file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py#265\u001b\\\u001b[2m265\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "dict_keys(['observation.images.left', 'observation.images.top', 'observation.images.right', 'action', 'observation.state', 'timestamp', 'frame_index', 'episode_index', 'index', 'task_index', 'general_task_index', 'action_is_pad', 'task', 'general_task', 'train_with_subtask'])"
            ]
          },
          "execution_count": 23,
=======
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SqYJJ1qFFqE",
        "outputId": "d8eabadd-739d-466f-db32-fef76e78b7c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 376, 672])"
            ]
          },
          "execution_count": 31,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
<<<<<<< HEAD
        "batch = next(dl_iter)\n",
        "batch.keys()"
=======
        "batch[\"observation.images.right\"].shape"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 24,
      "metadata": {},
=======
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-Sk63CMFcAf",
        "outputId": "24ad9f88-b156-49d0-ddec-8ae73ce1c459"
      },
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "dict_keys(['action', 'next.reward', 'next.done', 'next.truncated', 'info', 'action_is_pad', 'task', 'index', 'task_index', 'episode_index', 'train_with_subtask', 'subtask', 'subtask_tokens', 'observation.images.left', 'observation.images.top', 'observation.images.right', 'observation.state', 'observation.language.tokens', 'observation.language.attention_mask'])"
            ]
          },
          "execution_count": 24,
=======
              "torch.Size([2, 50, 14])"
            ]
          },
          "execution_count": 35,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
<<<<<<< HEAD
        "processed_ = preprocessor(batch)\n",
        "processed_.keys()"
=======
        "batch[\"action\"].shape"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 25,
      "metadata": {},
=======
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CakvsICFZ5J",
        "outputId": "25bc060e-cb62-41e7-fa49-344db35cf108"
      },
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "['Task: pick up the strawberry and put it in the basket. State: 6 0 253 194 57 39 0 255 -1 255 129 24 147 1 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128;\\nAction: ',\n",
              " 'Task: pick up the strawberry and put it in the basket. State: 19 0 255 193 20 41 1 255 -1 255 129 24 149 1 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128;\\nAction: ']"
            ]
          },
          "execution_count": 25,
=======
              "<lerobot.utils.logging_utils.MetricsTracker at 0x7e5b145e6840>"
            ]
          },
          "execution_count": 32,
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
<<<<<<< HEAD
        "task_ = processed_[\"task\"]\n",
        "task_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['action', 'next.reward', 'next.done', 'next.truncated', 'info', 'action_is_pad', 'task', 'index', 'task_index', 'episode_index', 'train_with_subtask', 'subtask', 'subtask_tokens', 'observation.images.left', 'observation.images.top', 'observation.images.right', 'observation.state', 'observation.language.tokens', 'observation.language.attention_mask'])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed = preprocessor.subtask(batch)\n",
        "processed.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Task: pick the fruits from the table and place them in the basket. Subtask: ',\n",
              " 'Task: pick the fruits from the table and place them in the basket. Subtask: ']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "task = processed[\"task\"]\n",
        "task"
=======
        "train_tracker"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awmcG7ICx4qQ",
        "outputId": "717a5a39-ab5a-49e2-d850-772de324bc20"
      },
      "outputs": [
        {
<<<<<<< HEAD
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11:02:59] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Loaded item with index <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>                                                 <a href=\"file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">xhuman_dataset.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py#265\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[11:02:59]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Loaded item with index \u001b[1;36m23\u001b[0m                                                 \u001b]8;id=311120;file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py\u001b\\\u001b[2mxhuman_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=228275;file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py#265\u001b\\\u001b[2m265\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Loaded item with index <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48</span>                                                 <a href=\"file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">xhuman_dataset.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py#265\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Loaded item with index \u001b[1;36m48\u001b[0m                                                 \u001b]8;id=63918;file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py\u001b\\\u001b[2mxhuman_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=784309;file:///home/lperez/main/nh/XHUMAN/xhuman/datasets/xhuman_dataset.py#265\u001b\\\u001b[2m265\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacity of 47.41 GiB of which 88.50 MiB is free. Process 2558670 has 13.99 GiB memory in use. Including non-PyTorch memory, this process has 33.32 GiB memory in use. Of the allocated memory 32.46 GiB is allocated by PyTorch, and 543.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m     batch = preprocessor(batch)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# print(batch)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Correcting the argument: pass the 'train_tracker' instance, not the 'MetricsTracker' class\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m train_tracker, output_dict = \u001b[43mupdate_policy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_tracker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrad_clip_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(train_tracker)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(output_dict)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mupdate_policy\u001b[39m\u001b[34m(train_metrics, step, policy, batch, optimizer, grad_clip_norm, accelerator, lr_scheduler, lock)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Optimizer step\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m lock \u001b[38;5;28;01mif\u001b[39;00m lock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m nullcontext():\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m optimizer.zero_grad()\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Step through pytorch scheduler at every batch instead of epoch\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/xhuman/lib/python3.12/site-packages/accelerate/optimizer.py:179\u001b[39m, in \u001b[36mAcceleratedOptimizer.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    177\u001b[39m         \u001b[38;5;28mself\u001b[39m._accelerate_step_called = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator_state.distributed_type == DistributedType.XLA:\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.gradient_state.is_xla_gradients_synced = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/xhuman/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:124\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m opt = opt_ref()\n\u001b[32m    123\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/xhuman/lib/python3.12/site-packages/torch/optim/optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/xhuman/lib/python3.12/site-packages/torch/optim/optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/xhuman/lib/python3.12/site-packages/torch/optim/adam.py:236\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    233\u001b[39m     state_steps: \u001b[38;5;28mlist\u001b[39m[Tensor] = []\n\u001b[32m    234\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     has_complex = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m     adam(\n\u001b[32m    247\u001b[39m         params_with_grad,\n\u001b[32m    248\u001b[39m         grads,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         decoupled_weight_decay=group[\u001b[33m\"\u001b[39m\u001b[33mdecoupled_weight_decay\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/xhuman/lib/python3.12/site-packages/torch/optim/adam.py:180\u001b[39m, in \u001b[36mAdam._init_group\u001b[39m\u001b[34m(self, group, params_with_grad, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[39m\n\u001b[32m    176\u001b[39m state[\u001b[33m\"\u001b[39m\u001b[33mexp_avg\u001b[39m\u001b[33m\"\u001b[39m] = torch.zeros_like(\n\u001b[32m    177\u001b[39m     p, memory_format=torch.preserve_format\n\u001b[32m    178\u001b[39m )\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# Exponential moving average of squared gradient values\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m state[\u001b[33m\"\u001b[39m\u001b[33mexp_avg_sq\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m    \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreserve_format\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[33m\"\u001b[39m\u001b[33mamsgrad\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# Maintains max of all exp. moving avg. of sq. grad. values\u001b[39;00m\n\u001b[32m    185\u001b[39m     state[\u001b[33m\"\u001b[39m\u001b[33mmax_exp_avg_sq\u001b[39m\u001b[33m\"\u001b[39m] = torch.zeros_like(\n\u001b[32m    186\u001b[39m         p, memory_format=torch.preserve_format\n\u001b[32m    187\u001b[39m     )\n",
            "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacity of 47.41 GiB of which 88.50 MiB is free. Process 2558670 has 13.99 GiB memory in use. Including non-PyTorch memory, this process has 33.32 GiB memory in use. Of the allocated memory 32.46 GiB is allocated by PyTorch, and 543.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
=======
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step:0 smpl:0 ep:0 epch:0.00 loss:30.665 grdn:202.285 lr:6.2e-08 updt_s:0.000 data_s:0.000\n",
            "{'ce_loss': 14.278895378112793, 'flow_matching_loss': 1.6530702114105225, 'total_loss': 30.80959701538086}\n",
            "step:0 smpl:0 ep:0 epch:0.00 loss:30.811 grdn:208.508 lr:7.5e-08 updt_s:0.000 data_s:0.000\n",
            "{'ce_loss': 14.0741548538208, 'flow_matching_loss': 1.7029062509536743, 'total_loss': 31.10321807861328}\n"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
          ]
        }
      ],
      "source": [
        "for step in range(0, 2): # Or however many steps you want\n",
<<<<<<< HEAD
        "    batch = next(dl_iter)\n",
        "    if step % 3 == 0:\n",
        "        batch = preprocessor.subtask(batch)\n",
        "    else:\n",
        "        batch = preprocessor(batch)\n",
=======
        "    # --- SAFE ITERATOR LOGIC ---\n",
        "    batch = next(dl_iter)\n",
        "    batch = preprocessor(batch)\n",
        "\n",
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
        "    # print(batch)\n",
        "    # Correcting the argument: pass the 'train_tracker' instance, not the 'MetricsTracker' class\n",
        "    train_tracker, output_dict = update_policy(\n",
        "        train_tracker,\n",
<<<<<<< HEAD
        "        step,\n",
=======
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
        "        policy,\n",
        "        batch,\n",
        "        optimizer,\n",
        "        cfg.optimizer.grad_clip_norm,\n",
        "        accelerator=accelerator,\n",
        "        lr_scheduler=lr_scheduler,\n",
        "    )\n",
        "    print(train_tracker)\n",
        "    print(output_dict)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
<<<<<<< HEAD
      "display_name": "xhuman",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
=======
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
>>>>>>> e8b3cb3b179fb0d4eb4bcbc0ce17a8022218f635
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0fe5f74de5954c3bb908f6e03e088c48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "248b0808370143c7badfe93e8d78db5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "390e710989aa43af9bdd6839905a871b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47dd9290227a499381c7cfea7d0838b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_390e710989aa43af9bdd6839905a871b",
            "style": "IPY_MODEL_ebb2207580b3425ca7532b227bc2bae3",
            "value": true
          }
        },
        "626687eb60af4fd792984b3ab343b7ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "644cf89777f0465aa226ac371e13696d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "656082c74aa1418db79a7065891605e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e92fa9a90f043ef85f3fb27680876b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7808c696eb9e4570b5951437e45d161b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "78966b95a97a452f98ea102e557e09bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_9fa8624b20a541ceb958a8a83804959e",
            "style": "IPY_MODEL_7808c696eb9e4570b5951437e45d161b",
            "tooltip": ""
          }
        },
        "939a93d871df42beb1870e66f196b13e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9517398565534022872338ed551ec0e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_626687eb60af4fd792984b3ab343b7ea",
            "placeholder": "",
            "style": "IPY_MODEL_656082c74aa1418db79a7065891605e1",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "963f3d45520b41d1b1e210a5bba1b457": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_a7390a71357e4c9ca4aed5331daca6d3",
            "placeholder": "",
            "style": "IPY_MODEL_939a93d871df42beb1870e66f196b13e",
            "value": ""
          }
        },
        "9c3832bec91f4242be3f80b2a6342993": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_0fe5f74de5954c3bb908f6e03e088c48"
          }
        },
        "9fa8624b20a541ceb958a8a83804959e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a244cf56c045450590cd3640b8b7eb34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_644cf89777f0465aa226ac371e13696d",
            "placeholder": "",
            "style": "IPY_MODEL_b382a2cbecd9412fb5fd181c0c46f994",
            "value": "Connecting..."
          }
        },
        "a7390a71357e4c9ca4aed5331daca6d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b382a2cbecd9412fb5fd181c0c46f994": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebb2207580b3425ca7532b227bc2bae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fabfff13e23d4b08a752940168cf69d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_248b0808370143c7badfe93e8d78db5d",
            "placeholder": "",
            "style": "IPY_MODEL_6e92fa9a90f043ef85f3fb27680876b3",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
