{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jorgemunozl/vla-test/blob/main/tests/train_val_pi05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2rYYgB4v8ry"
      },
      "source": [
        "# Fourtheen Test\n",
        "\n",
        "This test run the training using the same architecture that the scrip that we use for train seriosuly our models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Set this BEFORE importing pytorch/tensorflow\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "import torch\n",
        "# Check if it worked (should return 1 if you selected a single GPU)\n",
        "print(torch.cuda.device_count()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7zILqJ7Wv8rz"
      },
      "outputs": [],
      "source": [
        "from contextlib import nullcontext\n",
        "from typing import Any\n",
        "\n",
        "from accelerate import Accelerator\n",
        "from accelerate.utils import DistributedDataParallelKwargs\n",
        "from torch.optim import Optimizer\n",
        "\n",
        "from lerobot.configs import parser\n",
        "from lerobot.datasets.sampler import EpisodeAwareSampler\n",
        "from lerobot.datasets.utils import cycle\n",
        "from lerobot.optim.factory import make_optimizer_and_scheduler\n",
        "from lerobot.policies.pretrained import PreTrainedPolicy\n",
        "from lerobot.utils.logging_utils import AverageMeter, MetricsTracker\n",
        "from lerobot.utils.random_utils import set_seed\n",
        "from lerobot.utils.train_utils import load_training_state\n",
        "from lerobot.utils.utils import (\n",
        "    format_big_number,\n",
        "    has_method,\n",
        "    init_logging,\n",
        ")\n",
        "\n",
        "from xhuman.policies.factory import make_xhuman_policy, make_xhuman_pre_post_processors\n",
        "from xhuman.configs.train import TrainPipelineConfigXHUMAN\n",
        "from xhuman.datasets.factory import make_dataset_xhuman\n",
        "from xhuman.datasets.utils import split_train_eval_episodes\n",
        "from xhuman.logger import logger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYlyeGygv8r0"
      },
      "source": [
        "## Helper Functions\n",
        "\n",
        "These functions handle dataset loading and policy updates. They are designed to work with distributed training using HuggingFace Accelerate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CVmBxC-hv8r1"
      },
      "outputs": [],
      "source": [
        "def load_dataset(cfg: TrainPipelineConfigXHUMAN, episodes: list[int], is_main_process: bool = True, accelerator: Accelerator | None = None):\n",
        "    \"\"\"\n",
        "    Load the dataset for training and evaluation.\n",
        "    \"\"\"\n",
        "    # Dataset loading synchronization: main process downloads first to avoid race conditions\n",
        "    cfg.dataset.episodes = episodes\n",
        "    cfg.dataset.train_with_subtasks = True\n",
        "\n",
        "    if is_main_process:\n",
        "        logger.info(\"Creating dataset\")\n",
        "        dataset = make_dataset_xhuman(cfg)\n",
        "\n",
        "    accelerator.wait_for_everyone()\n",
        "\n",
        "    # Now all other processes can safely load the dataset\n",
        "    if not is_main_process:\n",
        "        dataset = make_dataset_xhuman(cfg)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iAqOQ9BS-8Xw"
      },
      "outputs": [],
      "source": [
        "def update_policy(\n",
        "    train_metrics: MetricsTracker,\n",
        "    step: int,\n",
        "    policy: PreTrainedPolicy,\n",
        "    batch: Any,\n",
        "    optimizer: Optimizer,\n",
        "    grad_clip_norm: float,\n",
        "    accelerator: Accelerator,\n",
        "    lr_scheduler=None,\n",
        "    lock=None,\n",
        ") -> tuple[MetricsTracker, dict]:\n",
        "    \"\"\"\n",
        "    Performs a single training step to update the policy's weights.\n",
        "\n",
        "    This function executes the forward and backward passes,\n",
        "    clips gradients, and steps the optimizer and\n",
        "    learning rate scheduler. Accelerator handles\n",
        "    mixed-precision training automatically.\n",
        "\n",
        "    Args:\n",
        "        train_metrics: A MetricsTracker instance to record training statistics.\n",
        "        policy: The policy model to be trained.\n",
        "        batch: A batch of training data.\n",
        "        optimizer: The optimizer used to update the policy's parameters.\n",
        "        grad_clip_norm: The maximum norm for gradient clipping.\n",
        "        accelerator: The Accelerator instance for distributed training and mixed precision.\n",
        "        lr_scheduler: An optional learning rate scheduler.\n",
        "        lock: An optional lock for thread-safe optimizer updates.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing:\n",
        "        - The updated MetricsTracker with new statistics for this step.\n",
        "        - A dictionary of outputs from the policy's forward pass, for logging purposes.\n",
        "    \"\"\"\n",
        "    policy.train()\n",
        "\n",
        "    # Let accelerator handle mixed precision\n",
        "    with accelerator.autocast():\n",
        "        if step % 3 == 0:\n",
        "            loss, output_dict = policy.forward_subtask(batch)\n",
        "        else:\n",
        "            loss, output_dict = policy.forward(batch)\n",
        "\n",
        "    # Use accelerator's backward method\n",
        "    accelerator.backward(loss)\n",
        "\n",
        "    # Clip gradients if specified\n",
        "    if grad_clip_norm > 0:\n",
        "        grad_norm = accelerator.clip_grad_norm_(policy.parameters(), grad_clip_norm)\n",
        "    else:\n",
        "        grad_norm = torch.nn.utils.clip_grad_norm_(\n",
        "            policy.parameters(), float(\"inf\"), error_if_nonfinite=False\n",
        "        )\n",
        "\n",
        "    # Optimizer step\n",
        "    with lock if lock is not None else nullcontext():\n",
        "        optimizer.step()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Step through pytorch scheduler at every batch instead of epoch\n",
        "    if lr_scheduler is not None:\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    # Update internal buffers if policy has update method\n",
        "    if has_method(accelerator.unwrap_model(policy, keep_fp32_wrapper=True), \"update\"):\n",
        "        accelerator.unwrap_model(policy, keep_fp32_wrapper=True).update()\n",
        "\n",
        "    # Track losses for logging\n",
        "    # total_loss is per-sample [B], so we track the mean\n",
        "    train_metrics.loss = loss.item()\n",
        "    train_metrics.grad_norm = grad_norm.item()\n",
        "    train_metrics.lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "    # Create output dictionary with tracked losses\n",
        "    output_dict = {\n",
        "        \"loss\": loss.mean().item(),\n",
        "    }\n",
        "\n",
        "    return train_metrics, output_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lK93NSNOuXsi"
      },
      "outputs": [],
      "source": [
        "from xhuman.policies.pi05ki.configuration_pi05ki import PI05KIConfig\n",
        "\n",
        "policy_config = PI05KIConfig(repo_id=\"none\",device=\"cuda\",pretrained_path=\"lerobot/pi05_base\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipXWi5oev8r2"
      },
      "source": [
        "## Configuration and Setup\n",
        "\n",
        "Configure your dataset and policy settings here. The dataset configuration specifies which HuggingFace repository to load, and the policy configuration sets up the PI05 model architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XEbEEWDbzMPT"
      },
      "outputs": [],
      "source": [
        "from xhuman.configs.default import LerobotDatasetConfig\n",
        "\n",
        "dataset_config = LerobotDatasetConfig(\n",
        "    repo_id=\"NONHUMAN-RESEARCH/test-general-idx\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IZ1d9a3Ov8r3"
      },
      "outputs": [],
      "source": [
        "cfg = TrainPipelineConfigXHUMAN(\n",
        "    dataset=dataset_config,\n",
        "    policy=policy_config # Example policy configuration, replace with your actual policy path\n",
        ")\n",
        "cfg.validate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgSIm33Qv8r3"
      },
      "source": [
        "## Training Setup\n",
        "\n",
        "Initialize the Accelerator for distributed training and set up the training environment. The accelerator automatically handles:\n",
        "- Multi-GPU training\n",
        "- Mixed precision training\n",
        "- Gradient synchronization across processes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XOJhp41Sv8r4"
      },
      "outputs": [],
      "source": [
        "# Create Accelerator\n",
        "# It will automatically detect if running in distributed mode or single-process mode\n",
        "# We set step_scheduler_with_optimizer=False to prevent accelerate from adjusting the lr_scheduler steps based on the num_processes\n",
        "# We set find_unused_parameters=True to handle models with conditional computation\n",
        "ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)\n",
        "accelerator = Accelerator(step_scheduler_with_optimizer=False, kwargs_handlers=[ddp_kwargs])\n",
        "\n",
        "init_logging(accelerator=accelerator)\n",
        "\n",
        "# Determine if this is the main process (for logging and checkpointing)\n",
        "is_main_process = accelerator.is_main_process\n",
        "\n",
        "# Set seed if specified\n",
        "if cfg.seed is not None:\n",
        "    set_seed(cfg.seed, accelerator=accelerator)\n",
        "\n",
        "# Use accelerator's device\n",
        "device = accelerator.device\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cuda.matmul.allow_tf32 = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "s_gB_Dpbv8r5",
        "outputId": "295de906-d49f-41c8-f458-1dd065450bde"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to read file '/home/lperez/.cache/huggingface/lerobot/NONHUMAN-RESEARCH/test-general-idx/data/chunk-000/file-000.parquet' with error <class 'datasets.table.CastError'>: Couldn't cast\n",
            "action: list<element: float>\n",
            "  child 0, element: float\n",
            "observation.state: list<element: float>\n",
            "  child 0, element: float\n",
            "timestamp: float\n",
            "frame_index: int64\n",
            "episode_index: int64\n",
            "index: int64\n",
            "task_index: int64\n",
            "general_task_index: int64\n",
            "-- schema metadata --\n",
            "pandas: '{\"index_columns\": [], \"column_indexes\": [], \"columns\": [{\"name\":' + 1051\n",
            "to\n",
            "{'action': List(Value('float32'), length=14), 'observation.state': List(Value('float32'), length=14), 'timestamp': Value('float32'), 'frame_index': Value('int64'), 'episode_index': Value('int64'), 'index': Value('int64'), 'task_index': Value('int64')}\n",
            "because column names don't match\n",
            "ERROR 2026-01-29 10:16:41 /parquet.py:108 Failed to read file '/home/lperez/.cache/huggingface/lerobot/NONHUMAN-RESEARCH/test-general-idx/data/chunk-000/file-000.parquet' with error <class 'datasets.table.CastError'>: Couldn't cast\n",
            "action: list<element: float>\n",
            "  child 0, element: float\n",
            "observation.state: list<element: float>\n",
            "  child 0, element: float\n",
            "timestamp: float\n",
            "frame_index: int64\n",
            "episode_index: int64\n",
            "index: int64\n",
            "task_index: int64\n",
            "general_task_index: int64\n",
            "-- schema metadata --\n",
            "pandas: '{\"index_columns\": [], \"column_indexes\": [], \"columns\": [{\"name\":' + 1051\n",
            "to\n",
            "{'action': List(Value('float32'), length=14), 'observation.state': List(Value('float32'), length=14), 'timestamp': Value('float32'), 'frame_index': Value('int64'), 'episode_index': Value('int64'), 'index': Value('int64'), 'task_index': Value('int64')}\n",
            "because column names don't match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Dataset loading failed with strict features (DatasetGenerationError). Retrying without features constraint.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10:16:41] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Total episodes available: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">437</span>                                                  <a href=\"file:///tmp/ipykernel_3131587/3893944116.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3893944116.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3131587/3893944116.py#16\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[10:16:41]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Total episodes available: \u001b[1;36m437\u001b[0m                                                  \u001b]8;id=370116;file:///tmp/ipykernel_3131587/3893944116.py\u001b\\\u001b[2m3893944116.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=65997;file:///tmp/ipykernel_3131587/3893944116.py#16\u001b\\\u001b[2m16\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> DEBUG MODE: Using only <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span> episodes                                            <a href=\"file:///tmp/ipykernel_3131587/3893944116.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3893944116.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3131587/3893944116.py#28\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m DEBUG MODE: Using only \u001b[1;36m200\u001b[0m episodes                                            \u001b]8;id=232594;file:///tmp/ipykernel_3131587/3893944116.py\u001b\\\u001b[2m3893944116.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=703849;file:///tmp/ipykernel_3131587/3893944116.py#28\u001b\\\u001b[2m28\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Loading train dataset with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">160</span> episodes                                        <a href=\"file:///tmp/ipykernel_3131587/3893944116.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3893944116.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3131587/3893944116.py#40\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">40</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Loading train dataset with \u001b[1;36m160\u001b[0m episodes                                        \u001b]8;id=723378;file:///tmp/ipykernel_3131587/3893944116.py\u001b\\\u001b[2m3893944116.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=210922;file:///tmp/ipykernel_3131587/3893944116.py#40\u001b\\\u001b[2m40\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Creating dataset                                                               <a href=\"file:///tmp/ipykernel_3131587/3578173160.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3578173160.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3131587/3578173160.py#10\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Creating dataset                                                               \u001b]8;id=459381;file:///tmp/ipykernel_3131587/3578173160.py\u001b\\\u001b[2m3578173160.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=943313;file:///tmp/ipykernel_3131587/3578173160.py#10\u001b\\\u001b[2m10\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Dataset loading failed with strict features (ValueError). Retrying without features constraint.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# Dataset Loading with Episode Filtering\n",
        "# ============================================================================\n",
        "# This cell loads the dataset with proper episode filtering.\n",
        "# For debugging: Set DEBUG_MODE = True to use only a subset of episodes\n",
        "# For production: Set DEBUG_MODE = False to use all available episodes\n",
        "\n",
        "DEBUG_MODE = True  # Set to False for full training\n",
        "DEBUG_MAX_EPISODES = 200  # Use only first N episodes for debugging\n",
        "\n",
        "# First, get total episodes count (load minimal dataset to check)\n",
        "if is_main_process:\n",
        "    temp_dataset = make_dataset_xhuman(cfg)\n",
        "    total_episodes = temp_dataset.meta.total_episodes\n",
        "    del temp_dataset\n",
        "    logger.info(f\"Total episodes available: {total_episodes}\")\n",
        "else:\n",
        "    # For non-main processes, use a reasonable default\n",
        "    # In practice, this will be synced after main process loads\n",
        "    total_episodes = 4  # Fallback - adjust if needed\n",
        "\n",
        "accelerator.wait_for_everyone()\n",
        "\n",
        "# Limit episodes for debugging\n",
        "if DEBUG_MODE:\n",
        "    episodes = list(range(min(DEBUG_MAX_EPISODES, total_episodes)))\n",
        "    if is_main_process:\n",
        "        logger.info(f\"DEBUG MODE: Using only {len(episodes)} episodes\")\n",
        "else:\n",
        "    episodes = list(range(total_episodes))\n",
        "\n",
        "# Split episodes\n",
        "train_episodes, eval_episodes = split_train_eval_episodes(\n",
        "    episodes, split_ratio=cfg.split_ratio, seed=42\n",
        ")\n",
        "\n",
        "# Load dataset with ONLY train episodes (proper way to filter)\n",
        "# This uses the load_dataset helper function which sets cfg.dataset.episodes\n",
        "if is_main_process:\n",
        "    logger.info(f\"Loading train dataset with {len(train_episodes)} episodes\")\n",
        "dataset = load_dataset(cfg, train_episodes, is_main_process=is_main_process, accelerator=accelerator)\n",
        "dataset.train_with_subtask = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "L2T_kvevv8r6",
        "outputId": "8aaa9681-4499-4985-c0a6-6ae97878351c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10:16:45] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Creating policy                                                                 <a href=\"file:///tmp/ipykernel_3131587/3499831122.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3499831122.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3131587/3499831122.py#3\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[10:16:45]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Creating policy                                                                 \u001b]8;id=354508;file:///tmp/ipykernel_3131587/3499831122.py\u001b\\\u001b[2m3499831122.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=22056;file:///tmp/ipykernel_3131587/3499831122.py#3\u001b\\\u001b[2m3\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from: lerobot/pi05_base\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING 2026-01-29 10:17:25 _pi05ki.py:1853 Vision embedding key might need handling: paligemma_with_expert.paligemma.model.vision_tower.vision_model.embeddings.patch_embedding.bias\n",
            "WARNING 2026-01-29 10:17:25 _pi05ki.py:1853 Vision embedding key might need handling: paligemma_with_expert.paligemma.model.vision_tower.vision_model.embeddings.patch_embedding.weight\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Loaded state dict from model.safetensors\n",
            "Remapped: action_in_proj.bias -> model.action_in_proj.bias\n",
            "Remapped: action_in_proj.weight -> model.action_in_proj.weight\n",
            "Remapped: action_out_proj.bias -> model.action_out_proj.bias\n",
            "Remapped: action_out_proj.weight -> model.action_out_proj.weight\n",
            "Remapped: paligemma_with_expert.gemma_expert.lm_head.weight -> model.paligemma_with_expert.gemma_expert.lm_head.weight\n",
            "Remapped: paligemma_with_expert.gemma_expert.model.layers.0.input_layernorm.dense.bias -> model.paligemma_with_expert.gemma_expert.model.layers.0.input_layernorm.dense.bias\n",
            "Remapped: paligemma_with_expert.gemma_expert.model.layers.0.input_layernorm.dense.weight -> model.paligemma_with_expert.gemma_expert.model.layers.0.input_layernorm.dense.weight\n",
            "Remapped: paligemma_with_expert.gemma_expert.model.layers.0.mlp.down_proj.weight -> model.paligemma_with_expert.gemma_expert.model.layers.0.mlp.down_proj.weight\n",
            "Remapped: paligemma_with_expert.gemma_expert.model.layers.0.mlp.gate_proj.weight -> model.paligemma_with_expert.gemma_expert.model.layers.0.mlp.gate_proj.weight\n",
            "Remapped: paligemma_with_expert.gemma_expert.model.layers.0.mlp.up_proj.weight -> model.paligemma_with_expert.gemma_expert.model.layers.0.mlp.up_proj.weight\n",
            "Remapped 812 state dict keys\n",
            "Warning: Could not remap state dict keys: Error(s) in loading state_dict for PI05KIPolicy:\n",
            "\tMissing key(s) in state_dict: \"model.paligemma_with_expert.paligemma.model.language_model.embed_tokens.weight\". \n"
          ]
        }
      ],
      "source": [
        "# Create policy\n",
        "if is_main_process:\n",
        "    logger.info(\"Creating policy\")\n",
        "policy = make_xhuman_policy(\n",
        "    cfg=cfg.policy,\n",
        "    ds_meta=dataset.meta,\n",
        ")\n",
        "\n",
        "accelerator.wait_for_everyone()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WeVjdudv8r6"
      },
      "source": [
        "## Dataset and Model Information\n",
        "\n",
        "Display metadata about the loaded dataset and model. This includes:\n",
        "- Total number of episodes and frames\n",
        "- Model parameter counts\n",
        "- Effective batch size (accounting for distributed training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4cFEE9pv8r6",
        "outputId": "846663c9-d50d-460f-ece2-78627fa04e86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "DATASET METADATA\n",
            "================================================================================\n",
            "\n",
            "Dataset Repository: NONHUMAN-RESEARCH/test-general-idx\n",
            "Total Episodes: 437\n",
            "Training Episodes: 160\n",
            "Number of Frames: 151,548\n",
            "Number of Episodes (loaded): 160\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Display dataset metadata and model configuration\n",
        "if is_main_process:\n",
        "    from pprint import pprint\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"DATASET METADATA\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"\\nDataset Repository: {dataset.repo_id}\")\n",
        "    print(f\"Total Episodes: {dataset.meta.total_episodes}\")\n",
        "    print(f\"Training Episodes: {len(train_episodes)}\")\n",
        "    print(f\"Number of Frames: {dataset.num_frames:,}\")\n",
        "    print(f\"Number of Episodes (loaded): {dataset.num_episodes}\")\n",
        "\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ADIBf_oF0T0_"
      },
      "outputs": [],
      "source": [
        "processor_kwargs = {}\n",
        "postprocessor_kwargs = {}\n",
        "\n",
        "if (cfg.policy.pretrained_path and not cfg.resume) or not cfg.policy.pretrained_path:\n",
        "    processor_kwargs[\"dataset_stats\"] = dataset.meta.stats\n",
        "\n",
        "if cfg.policy.pretrained_path is not None:\n",
        "    processor_kwargs[\"preprocessor_overrides\"] = {\n",
        "        \"device_processor\": {\"device\": device.type},\n",
        "        \"normalizer_processor\": {\n",
        "            \"stats\": dataset.meta.stats,\n",
        "            \"features\": {**policy.config.input_features, **policy.config.output_features},\n",
        "            \"norm_map\": policy.config.normalization_mapping,\n",
        "        },\n",
        "    }\n",
        "    postprocessor_kwargs[\"postprocessor_overrides\"] = {\n",
        "        \"unnormalizer_processor\": {\n",
        "            \"stats\": dataset.meta.stats,\n",
        "            \"features\": policy.config.output_features,\n",
        "            \"norm_map\": policy.config.normalization_mapping,\n",
        "        },\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rcEUR_P1v8r7"
      },
      "outputs": [],
      "source": [
        "# Create processors\n",
        "preprocessor, postprocessor = make_xhuman_pre_post_processors(\n",
        "    policy_cfg=cfg.policy,\n",
        "    **processor_kwargs,\n",
        "    **postprocessor_kwargs,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer, lr_scheduler = make_optimizer_and_scheduler(cfg, policy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Zj87lmHcv8r7",
        "outputId": "5641eaeb-1a99-48d9-fa41-98e1157775c0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10:17:28] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Creating optimizer and scheduler                                                 <a href=\"file:///tmp/ipykernel_3131587/368181672.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">368181672.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3131587/368181672.py#3\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[10:17:28]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Creating optimizer and scheduler                                                 \u001b]8;id=74441;file:///tmp/ipykernel_3131587/368181672.py\u001b\\\u001b[2m368181672.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=742225;file:///tmp/ipykernel_3131587/368181672.py#3\u001b\\\u001b[2m3\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create optimizer and scheduler\n",
        "if is_main_process:\n",
        "    logger.info(\"Creating optimizer and scheduler\")\n",
        "\n",
        "step = 0  # number of policy updates\n",
        "\n",
        "# Resume from checkpoint if needed\n",
        "if cfg.resume:\n",
        "    step, optimizer, lr_scheduler = load_training_state(cfg.checkpoint_path, optimizer, lr_scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "E_d1t5DWv8r8",
        "outputId": "0c7d5f85-138d-4cf1-ae28-99b1bfc410da"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Output dir: outputs/train/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2026</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>-41_pi05_ki                           <a href=\"file:///tmp/ipykernel_3131587/4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3131587/4288334519.py#5\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Output dir: outputs/train/\u001b[1;36m2026\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m29\u001b[0m/\u001b[1;36m10\u001b[0m-\u001b[1;36m16\u001b[0m-41_pi05_ki                           \u001b]8;id=901393;file:///tmp/ipykernel_3131587/4288334519.py\u001b\\\u001b[2m4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=346479;file:///tmp/ipykernel_3131587/4288334519.py#5\u001b\\\u001b[2m5\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Steps: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100000</span> <span style=\"font-weight: bold\">(</span>100K<span style=\"font-weight: bold\">)</span>                                                            <a href=\"file:///tmp/ipykernel_3131587/4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3131587/4288334519.py#6\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Steps: \u001b[1;36m100000\u001b[0m \u001b[1m(\u001b[0m100K\u001b[1m)\u001b[0m                                                            \u001b]8;id=508993;file:///tmp/ipykernel_3131587/4288334519.py\u001b\\\u001b[2m4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=224643;file:///tmp/ipykernel_3131587/4288334519.py#6\u001b\\\u001b[2m6\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Dataset frames: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">151548</span> <span style=\"font-weight: bold\">(</span>152K<span style=\"font-weight: bold\">)</span>                                                   <a href=\"file:///tmp/ipykernel_3131587/4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3131587/4288334519.py#7\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">7</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Dataset frames: \u001b[1;36m151548\u001b[0m \u001b[1m(\u001b[0m152K\u001b[1m)\u001b[0m                                                   \u001b]8;id=598782;file:///tmp/ipykernel_3131587/4288334519.py\u001b\\\u001b[2m4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=604201;file:///tmp/ipykernel_3131587/4288334519.py#7\u001b\\\u001b[2m7\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Dataset episodes: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">160</span>                                                           <a href=\"file:///tmp/ipykernel_3131587/4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3131587/4288334519.py#8\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Dataset episodes: \u001b[1;36m160\u001b[0m                                                           \u001b]8;id=426833;file:///tmp/ipykernel_3131587/4288334519.py\u001b\\\u001b[2m4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=199659;file:///tmp/ipykernel_3131587/4288334519.py#8\u001b\\\u001b[2m8\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Effective batch size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> x <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>                                                <a href=\"file:///tmp/ipykernel_3131587/4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3131587/4288334519.py#11\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Effective batch size: \u001b[1;36m8\u001b[0m x \u001b[1;36m1\u001b[0m = \u001b[1;36m8\u001b[0m                                                \u001b]8;id=444154;file:///tmp/ipykernel_3131587/4288334519.py\u001b\\\u001b[2m4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=431071;file:///tmp/ipykernel_3131587/4288334519.py#11\u001b\\\u001b[2m11\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Learnable params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3616757520</span> <span style=\"font-weight: bold\">(</span>4B<span style=\"font-weight: bold\">)</span>                                              <a href=\"file:///tmp/ipykernel_3131587/4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3131587/4288334519.py#12\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Learnable params: \u001b[1;36m3616757520\u001b[0m \u001b[1m(\u001b[0m4B\u001b[1m)\u001b[0m                                              \u001b]8;id=685197;file:///tmp/ipykernel_3131587/4288334519.py\u001b\\\u001b[2m4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=677568;file:///tmp/ipykernel_3131587/4288334519.py#12\u001b\\\u001b[2m12\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Total params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3616757520</span> <span style=\"font-weight: bold\">(</span>4B<span style=\"font-weight: bold\">)</span>                                                  <a href=\"file:///tmp/ipykernel_3131587/4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3131587/4288334519.py#13\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Total params: \u001b[1;36m3616757520\u001b[0m \u001b[1m(\u001b[0m4B\u001b[1m)\u001b[0m                                                  \u001b]8;id=839482;file:///tmp/ipykernel_3131587/4288334519.py\u001b\\\u001b[2m4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=903529;file:///tmp/ipykernel_3131587/4288334519.py#13\u001b\\\u001b[2m13\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Print training info\n",
        "if is_main_process:\n",
        "    num_learnable_params = sum(p.numel() for p in policy.parameters() if p.requires_grad)\n",
        "    num_total_params = sum(p.numel() for p in policy.parameters())\n",
        "    logger.info(f\"Output dir: {cfg.output_dir}\")\n",
        "    logger.info(f\"Steps: {cfg.steps} ({format_big_number(cfg.steps)})\")\n",
        "    logger.info(f\"Dataset frames: {dataset.num_frames} ({format_big_number(dataset.num_frames)})\")\n",
        "    logger.info(f\"Dataset episodes: {dataset.num_episodes}\")\n",
        "    num_processes = accelerator.num_processes\n",
        "    effective_bs = cfg.batch_size * num_processes\n",
        "    logger.info(f\"Effective batch size: {cfg.batch_size} x {num_processes} = {effective_bs}\")\n",
        "    logger.info(f\"Learnable params: {num_learnable_params} ({format_big_number(num_learnable_params)})\")\n",
        "    logger.info(f\"Total params: {num_total_params} ({format_big_number(num_total_params)})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "jAOHZFNwv8r8",
        "outputId": "417243eb-a1d9-4a54-a882-a2cf21c6480f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Not dropping any frames                                                        <a href=\"file:///tmp/ipykernel_3131587/4111286182.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4111286182.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3131587/4111286182.py#12\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Not dropping any frames                                                        \u001b]8;id=146991;file:///tmp/ipykernel_3131587/4111286182.py\u001b\\\u001b[2m4111286182.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=442374;file:///tmp/ipykernel_3131587/4111286182.py#12\u001b\\\u001b[2m12\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create dataloader\n",
        "if hasattr(cfg.policy, \"drop_n_last_frames\"):\n",
        "    logger.info(f\"Dropping {cfg.policy.drop_n_last_frames} last frames\")\n",
        "    shuffle = False\n",
        "    sampler = EpisodeAwareSampler(\n",
        "        dataset.meta.episodes[\"dataset_from_index\"],\n",
        "        dataset.meta.episodes[\"dataset_to_index\"],\n",
        "        drop_n_last_frames=cfg.policy.drop_n_last_frames,\n",
        "        shuffle=True,\n",
        "    )\n",
        "else:\n",
        "    logger.info(\"Not dropping any frames\")\n",
        "    shuffle = True\n",
        "    sampler = None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hSpoN-wy-8X3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Now create your loader normally\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    drop_last=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "uMGOkAcg-8X4"
      },
      "outputs": [],
      "source": [
        "# Prepare everything with accelerator\n",
        "accelerator.wait_for_everyone()\n",
        "policy, optimizer, dataloader, lr_scheduler = accelerator.prepare(\n",
        "    policy, optimizer, train_dataloader, lr_scheduler\n",
        ")\n",
        "\n",
        "policy.train()\n",
        "\n",
        "# Setup metrics tracking\n",
        "train_metrics = {\n",
        "    \"loss\": AverageMeter(\"loss\", \":.3f\"),\n",
        "    \"grad_norm\": AverageMeter(\"grdn\", \":.3f\"),\n",
        "    \"lr\": AverageMeter(\"lr\", \":0.1e\"),\n",
        "    \"update_s\": AverageMeter(\"updt_s\", \":.3f\"),\n",
        "    \"dataloading_s\": AverageMeter(\"data_s\", \":.3f\"),\n",
        "}\n",
        "\n",
        "effective_batch_size = cfg.batch_size * accelerator.num_processes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JZKSXs7r-8X4"
      },
      "outputs": [],
      "source": [
        "train_tracker = MetricsTracker(\n",
        "    effective_batch_size,\n",
        "    dataset.num_frames,\n",
        "    dataset.num_episodes,\n",
        "    train_metrics,\n",
        "    initial_step=step,\n",
        "    accelerator=accelerator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "cF1NkqcTobVj",
        "outputId": "a4de313e-7628-4893-fe82-d762d0df3542"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\ndataloader = torch.utils.data.DataLoader(\\n    dataset,\\n    num_workers=cfg.num_workers,\\n    batch_size=2,\\n    shuffle=shuffle and not cfg.dataset.streaming,\\n    sampler=sampler,\\n    pin_memory=device.type == \"cuda\",\\n    drop_last=False,\\n    prefetch_factor=2 if cfg.num_workers > 0 else None,\\n)\\n'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    num_workers=cfg.num_workers,\n",
        "    batch_size=2,\n",
        "    shuffle=shuffle and not cfg.dataset.streaming,\n",
        "    sampler=sampler,\n",
        "    pin_memory=device.type == \"cuda\",\n",
        "    drop_last=False,\n",
        "    prefetch_factor=2 if cfg.num_workers > 0 else None,\n",
        ")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "n7wHY5Q_7EMt",
        "outputId": "34ca52f3-ea14-4457-d26f-cd490482c9b8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Start offline training on a fixed dataset                                       <a href=\"file:///tmp/ipykernel_3131587/2557974599.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2557974599.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3131587/2557974599.py#4\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Start offline training on a fixed dataset                                       \u001b]8;id=79046;file:///tmp/ipykernel_3131587/2557974599.py\u001b\\\u001b[2m2557974599.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=464656;file:///tmp/ipykernel_3131587/2557974599.py#4\u001b\\\u001b[2m4\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Train episodes: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">160</span>                                                             <a href=\"file:///tmp/ipykernel_3131587/2557974599.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2557974599.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3131587/2557974599.py#5\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Train episodes: \u001b[1;36m160\u001b[0m                                                             \u001b]8;id=53045;file:///tmp/ipykernel_3131587/2557974599.py\u001b\\\u001b[2m2557974599.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=683823;file:///tmp/ipykernel_3131587/2557974599.py#5\u001b\\\u001b[2m5\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Total training steps: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100000</span>                                                    <a href=\"file:///tmp/ipykernel_3131587/2557974599.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2557974599.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3131587/2557974599.py#6\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Total training steps: \u001b[1;36m100000\u001b[0m                                                    \u001b]8;id=790170;file:///tmp/ipykernel_3131587/2557974599.py\u001b\\\u001b[2m2557974599.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=889921;file:///tmp/ipykernel_3131587/2557974599.py#6\u001b\\\u001b[2m6\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Training initialization\n",
        "# This logs the start of training and shows how many episodes will be used\n",
        "if is_main_process:\n",
        "    logger.info(\"Start offline training on a fixed dataset\")\n",
        "    logger.info(f\"Train episodes: {len(train_episodes)}\")\n",
        "    logger.info(f\"Total training steps: {cfg.steps}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "tj-vGUvo-8X5"
      },
      "outputs": [],
      "source": [
        "dl_iter = cycle(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['observation.images.left', 'observation.images.top', 'observation.images.right', 'action', 'observation.state', 'timestamp', 'frame_index', 'episode_index', 'index', 'task_index', 'general_task_index', 'action_is_pad', 'task', 'general_task', 'train_with_subtask'])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch = next(dl_iter)\n",
        "batch.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['action', 'next.reward', 'next.done', 'next.truncated', 'info', 'action_is_pad', 'task', 'index', 'task_index', 'episode_index', 'train_with_subtask', 'subtask', 'subtask_tokens', 'observation.images.left', 'observation.images.top', 'observation.images.right', 'observation.state', 'observation.language.tokens', 'observation.language.attention_mask'])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed = preprocessor.subtask(batch)\n",
        "processed.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: LINE 1089 modeling_pi05ki.py: final_loss: \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor(2.2335, device='cuda:0', grad_fn=<MeanBackward0>),\n",
              " {'vlm_loss': 2.2334561347961426})"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss = policy.forward_subtask(processed)\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lerobot.utils.constants import OBS_LANGUAGE_TOKENS, OBS_LANGUAGE_ATTENTION_MASK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "images, img_masks = policy._preprocess_images(batch)\n",
        "tokens = processed[f\"{OBS_LANGUAGE_TOKENS}\"]\n",
        "masks = processed[f\"{OBS_LANGUAGE_ATTENTION_MASK}\"]\n",
        "subtasks_tokenized = processed[\"subtask_tokens\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          ...,\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.]],\n",
              "\n",
              "         [[-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          ...,\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.]],\n",
              "\n",
              "         [[-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          ...,\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.]]],\n",
              "\n",
              "\n",
              "        [[[-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          ...,\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.]],\n",
              "\n",
              "         [[-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          ...,\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.]],\n",
              "\n",
              "         [[-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          ...,\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.]]]], device='cuda:0')"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          ...,\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.]],\n",
              "\n",
              "         [[-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          ...,\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.]],\n",
              "\n",
              "         [[-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          ...,\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.]]],\n",
              "\n",
              "\n",
              "        [[[-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          ...,\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.]],\n",
              "\n",
              "         [[-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          ...,\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.]],\n",
              "\n",
              "         [[-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          ...,\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.],\n",
              "          [-3., -3., -3.,  ..., -3., -3., -3.]]]], device='cuda:0')"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([True, True], device='cuda:0'),\n",
              " tensor([True, True], device='cuda:0'),\n",
              " tensor([True, True], device='cuda:0')]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([False, False], device='cuda:0'),\n",
              " tensor([True, True], device='cuda:0'),\n",
              " tensor([False, False], device='cuda:0')]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xhuman.policies.pi05ki.modeling_pi05ki import make_att_2d_masks\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "        img_masks = [torch.zeros_like(img_masks[0]), torch.ones_like(img_masks[0]), torch.zeros_like(img_masks[0])]  # noqa: E501\n",
        "        tokens = tokens.clone()\n",
        "\n",
        "        pad_positions = (tokens == 0).int().argmax(dim=1)\n",
        "        # If no padding token found, set to sequence length\n",
        "        no_pad_mask = (tokens == 0).any(dim=1)\n",
        "        pad_positions = torch.where(\n",
        "            no_pad_mask, pad_positions, tokens.shape[1]\n",
        "        )\n",
        "        token_loss_mask = torch.zeros_like(\n",
        "            tokens, dtype=torch.bool, device=tokens.device\n",
        "        )\n",
        "\n",
        "        list_len_subtask = [t.shape[0] for t in subtasks_tokenized]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Task: pick the fruits from the table and place them in the basket. Subtask:'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "policy._detokenize_subtask(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/paligemma-3b-pt-224\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<bos>Task: pick the fruits from the table and place them in the basket. Subtask: <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
              " '<bos>Task: pick the fruits from the table and place them in the basket. Subtask: <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "detokenized_tokens = tokenizer.batch_decode(tokens)\n",
        "detokenized_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "        for i in range(tokens.shape[0]):\n",
        "            pad_idx = pad_positions[i].item()\n",
        "            discrete_len = list_len_subtask[i]\n",
        "            subtask_tokens = subtasks_tokenized[i].to(\n",
        "                device=tokens.device, dtype=tokens.dtype\n",
        "            )\n",
        "\n",
        "            # Check if discrete actions fit in the sequence\n",
        "            if pad_idx + discrete_len > tokens.shape[1]:\n",
        "                # Truncate discrete actions if they don't fit\n",
        "                available_space = tokens.shape[1] - pad_idx\n",
        "                if available_space > 0:\n",
        "                    subtask_tokens = subtask_tokens[:available_space]\n",
        "                    discrete_len = available_space\n",
        "                else:\n",
        "                    # No space available, skip this sample's discrete actions\n",
        "                    continue\n",
        "\n",
        "            # Insert discrete action tokens at padding position\n",
        "            tokens[i, pad_idx:pad_idx + discrete_len] = subtask_tokens\n",
        "            # Mark these positions for loss computation\n",
        "            token_loss_mask[i, pad_idx:pad_idx + discrete_len] = True\n",
        "            # Mark discrete action positions as valid (True) in masks\n",
        "            masks[i, pad_idx:pad_idx + discrete_len] = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "          True, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "          True, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False]],\n",
              "       device='cuda:0')"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token_loss_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "          True, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False],\n",
              "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "          True, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False]],\n",
              "       device='cuda:0')"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([20, 20], device='cuda:0')"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pad_positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0, device='cuda:0')"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens[0][41]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "es\n",
            "es\n"
          ]
        }
      ],
      "source": [
        "        prefix_embs, prefix_pad_masks, prefix_att_masks = policy.model.embed_prefix(\n",
        "            images, img_masks, tokens, masks,\n",
        "        )\n",
        "        prefix_att_masks = prefix_att_masks.clone()\n",
        "\n",
        "        num_image_embs = prefix_embs.shape[1] - tokens.shape[1]\n",
        "\n",
        "        # Causal masking for discrete actions\n",
        "        for i in range(tokens.shape[0]):\n",
        "            pad_idx = pad_positions[i].item()\n",
        "            discrete_len = list_len_subtask[i]\n",
        "\n",
        "            if pad_idx + discrete_len <= tokens.shape[1]:\n",
        "                discrete_action_start_idx = num_image_embs + pad_idx\n",
        "                discrete_action_end_idx = (\n",
        "                    discrete_action_start_idx + discrete_len\n",
        "                )\n",
        "\n",
        "                if discrete_action_end_idx <= prefix_att_masks.shape[1]:\n",
        "                    print(\"es\")\n",
        "                    prefix_att_masks[\n",
        "                        i, discrete_action_start_idx:discrete_action_end_idx\n",
        "                    ] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(True, device='cuda:0')"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prefix_att_masks[0][790]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "799"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "discrete_action_end_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "788"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "discrete_action_start_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 968])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prefix_att_masks.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "        att_2d_masks = make_att_2d_masks(prefix_pad_masks, prefix_att_masks)\n",
        "        position_ids = torch.cumsum(prefix_pad_masks, dim=1) - 1\n",
        "        att_2d_masks_4d = policy.model._prepare_attention_masks_4d(\n",
        "            att_2d_masks, dtype=prefix_embs.dtype\n",
        "        )\n",
        "\n",
        "        def forward_func(prefix_embs, att_2d_masks_4d, position_ids):\n",
        "            (prefix_out, _), _ = policy.model.paligemma_with_expert.forward(\n",
        "                attention_mask=att_2d_masks_4d,\n",
        "                position_ids=position_ids,\n",
        "                past_key_values=None,\n",
        "                inputs_embeds=[prefix_embs, None],\n",
        "                use_cache=False,\n",
        "                adarms_cond=[None, None],\n",
        "            )\n",
        "            return prefix_out\n",
        "\n",
        "        prefix_out = policy.model._apply_checkpoint(\n",
        "            forward_func, prefix_embs, att_2d_masks_4d, position_ids\n",
        "        )\n",
        "\n",
        "        # prefix_out shape: [B, prefix_seq_len, hidden_dim]\n",
        "        def lm_head_func(prefix_out):\n",
        "            return policy.model.paligemma_with_expert.paligemma.lm_head(prefix_out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "        logits = policy.model._apply_checkpoint(lm_head_func, prefix_out)\n",
        "\n",
        "        num_image_embs = prefix_embs.shape[1] - tokens.shape[1]\n",
        "        lang_logits = logits[:, num_image_embs:, :]\n",
        "\n",
        "        # shift_logits shape: [B, lang_seq_len-1, vocab_size]\n",
        "        shift_logits = lang_logits[:, :-1, :].contiguous()\n",
        "\n",
        "        # shift_labels shape: [B, lang_seq_len-1]\n",
        "        shift_labels = tokens[:, 1:].contiguous()\n",
        "\n",
        "        # shift_mask shape: [B, lang_seq_len-1]\n",
        "        shift_mask = token_loss_mask[:, 1:].contiguous()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "        shift_labels = shift_labels.masked_fill(shift_mask == 0, -100)\n",
        "\n",
        "        flat_logits = shift_logits.view(-1, shift_logits.size(-1))\n",
        "        flat_labels = shift_labels.view(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# 3. Compute Loss\n",
        "# reduction='sum' is usually safer/easier here if we manually normalize later,\n",
        "# but 'none' allows you to inspect per-sample loss if needed.\n",
        "loss_per_token = F.cross_entropy(\n",
        "    flat_logits, \n",
        "    flat_labels, \n",
        "    reduction='none', \n",
        "    ignore_index=-100 # This handles the masking internally!\n",
        ")\n",
        "\n",
        "# Reshape back to [B, seq_len]\n",
        "loss_per_token = loss_per_token.view(shift_labels.shape[0], -1)\n",
        "\n",
        "# 4. Correct Reduction\n",
        "# Option A: Global Batch Average (Most common for pre-training/finetuning)\n",
        "# Sum all losses / Total valid tokens\n",
        "total_loss = loss_per_token.sum()\n",
        "total_valid_tokens = shift_mask.sum()\n",
        "final_loss = total_loss / (total_valid_tokens + 1e-8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(14.0556, device='cuda:0', grad_fn=<DivBackward0>)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_loss"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "xhuman_nh",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0fe5f74de5954c3bb908f6e03e088c48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "248b0808370143c7badfe93e8d78db5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "390e710989aa43af9bdd6839905a871b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47dd9290227a499381c7cfea7d0838b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_390e710989aa43af9bdd6839905a871b",
            "style": "IPY_MODEL_ebb2207580b3425ca7532b227bc2bae3",
            "value": true
          }
        },
        "626687eb60af4fd792984b3ab343b7ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "644cf89777f0465aa226ac371e13696d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "656082c74aa1418db79a7065891605e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e92fa9a90f043ef85f3fb27680876b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7808c696eb9e4570b5951437e45d161b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "78966b95a97a452f98ea102e557e09bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_9fa8624b20a541ceb958a8a83804959e",
            "style": "IPY_MODEL_7808c696eb9e4570b5951437e45d161b",
            "tooltip": ""
          }
        },
        "939a93d871df42beb1870e66f196b13e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9517398565534022872338ed551ec0e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_626687eb60af4fd792984b3ab343b7ea",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_656082c74aa1418db79a7065891605e1",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "963f3d45520b41d1b1e210a5bba1b457": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_a7390a71357e4c9ca4aed5331daca6d3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_939a93d871df42beb1870e66f196b13e",
            "value": ""
          }
        },
        "9c3832bec91f4242be3f80b2a6342993": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_0fe5f74de5954c3bb908f6e03e088c48"
          }
        },
        "9fa8624b20a541ceb958a8a83804959e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a244cf56c045450590cd3640b8b7eb34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_644cf89777f0465aa226ac371e13696d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b382a2cbecd9412fb5fd181c0c46f994",
            "value": "Connecting..."
          }
        },
        "a7390a71357e4c9ca4aed5331daca6d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b382a2cbecd9412fb5fd181c0c46f994": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebb2207580b3425ca7532b227bc2bae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fabfff13e23d4b08a752940168cf69d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_248b0808370143c7badfe93e8d78db5d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6e92fa9a90f043ef85f3fb27680876b3",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
