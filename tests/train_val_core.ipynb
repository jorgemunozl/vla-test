{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2rYYgB4v8ry"
      },
      "source": [
        "# Core Training Notebook\n",
        "\n",
        "This notebook contains the essential components for training a PI05 policy:\n",
        "\n",
        "## What's Included\n",
        "- **Dataset Loading**: Load and filter episodes from HuggingFace datasets\n",
        "- **Policy Setup**: Initialize PI05 policy with proper configuration\n",
        "- **Training Loop**: Core training loop with gradient updates and metrics tracking\n",
        "\n",
        "## What's Excluded\n",
        "- Evaluation loops\n",
        "- WandB logging\n",
        "- Checkpoint saving strategies\n",
        "- Model inference/testing\n",
        "\n",
        "## Usage\n",
        "1. Set your dataset and policy configuration in the configuration cells\n",
        "2. Enable `DEBUG_MODE = True` for quick testing with a subset of episodes\n",
        "3. Set `DEBUG_MODE = False` for full training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "The following cells set up the environment:\n",
        "1. Clone the XHUMAN repository\n",
        "2. Install dependencies\n",
        "3. Authenticate with HuggingFace Hub\n",
        "4. Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wgo2DrQ1wF5C",
        "outputId": "24a2eeeb-d9cf-42a4-d2ca-f91e56a3ec1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'XHUMAN'...\n",
            "remote: Enumerating objects: 2067, done.\u001b[K\n",
            "remote: Counting objects: 100% (273/273), done.\u001b[K\n",
            "remote: Compressing objects: 100% (170/170), done.\u001b[K\n",
            "remote: Total 2067 (delta 171), reused 178 (delta 100), pack-reused 1794 (from 2)\u001b[K\n",
            "Receiving objects: 100% (2067/2067), 7.81 MiB | 15.44 MiB/s, done.\n",
            "Resolving deltas: 100% (1314/1314), done.\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFr64v0rwSM8",
        "outputId": "5385f9fc-2bfe-4afa-c0ce-28c439a4b2bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/XHUMAN\n"
          ]
        }
      ],
      "source": [
        "%cd XHUMAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljAwUMsOwm9P",
        "outputId": "8b4e0f55-a60c-4718-da59-6bf3b774c8e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m215 packages\u001b[0m \u001b[2min 500ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 796ms\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 0.37ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 0.84ms\u001b[0m\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mxhuman\u001b[0m\u001b[2m==0.1.0 (from file:///content/XHUMAN/XHUMAN)\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mxhuman\u001b[0m\u001b[2m==0.1.0 (from file:///content/XHUMAN)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!uv pip install -e .[pi]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "223635f477ae4dd1979d9ccffedf217c",
            "2c00b0e1ccb84d738efb8b7edbab1ec9",
            "6b059a56590b42f89cc4dab7f9a39c6e",
            "977753a82157430f96b7edd621de13d1",
            "7ba69367713444238891a999e4f4edc9",
            "34f50fe3202c4af9950768fb2e3adb44",
            "e32221c2a4c54597a0055f310d820f18",
            "d2b69de2f22d481d835951be4082c268",
            "a5ddfc2dbeda4962b3eefedf942570b9",
            "f87e9e5fe39043c782fc5b97d7481a45",
            "59e7d62281b247e283295f66340518e6",
            "cf300958c285470fb4f5727bbbaf6364",
            "c3f4563188db4314bdeb9fa74801e238",
            "83e28ff7d8084a66afd78d2309b63f85",
            "4f51c0d79c4f460fb2bf4032f85dd059",
            "24715984bee94afaa73dee4cb075ca61",
            "8c297db32b614e08983c241e91d3027f",
            "75c051939f5545929beedce2030d65d0",
            "58f5a99f270e4ae299031956a56a4bdc",
            "5061f9c62d9b47d8acc7ecfd1209035e"
          ]
        },
        "id": "BlAiJpEFwoa4",
        "outputId": "7c46969c-3329-4490-af02-afc5b3a6cc88"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "223635f477ae4dd1979d9ccffedf217c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zILqJ7Wv8rz",
        "outputId": "02c2f24c-8966-46d9-841f-7c6b4320817d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ESO\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from contextlib import nullcontext\n",
        "from typing import Any\n",
        "\n",
        "import torch\n",
        "from accelerate import Accelerator\n",
        "from accelerate.utils import DistributedDataParallelKwargs\n",
        "from torch.optim import Optimizer\n",
        "\n",
        "from lerobot.configs import parser\n",
        "from lerobot.datasets.sampler import EpisodeAwareSampler\n",
        "from lerobot.datasets.utils import cycle\n",
        "from lerobot.optim.factory import make_optimizer_and_scheduler\n",
        "from lerobot.policies.pretrained import PreTrainedPolicy\n",
        "from lerobot.utils.logging_utils import AverageMeter, MetricsTracker\n",
        "from lerobot.utils.random_utils import set_seed\n",
        "from lerobot.utils.train_utils import load_training_state\n",
        "from lerobot.utils.utils import (\n",
        "    format_big_number,\n",
        "    has_method,\n",
        "    init_logging,\n",
        ")\n",
        "\n",
        "from xhuman.policies.factory import make_xhuman_policy, make_xhuman_pre_post_processors\n",
        "from xhuman.configs.train import TrainPipelineConfigXHUMAN\n",
        "from xhuman.datasets.factory import make_dataset_xhuman\n",
        "from xhuman.datasets.utils import split_train_eval_episodes\n",
        "from xhuman.logger import logger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYlyeGygv8r0"
      },
      "source": [
        "## Helper Functions\n",
        "\n",
        "These functions handle dataset loading and policy updates. They are designed to work with distributed training using HuggingFace Accelerate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CVmBxC-hv8r1"
      },
      "outputs": [],
      "source": [
        "def load_dataset(cfg: TrainPipelineConfigXHUMAN, episodes: list[int], is_main_process: bool = True, accelerator: Accelerator | None = None):\n",
        "    \"\"\"\n",
        "    Load the dataset for training and evaluation.\n",
        "    \"\"\"\n",
        "    # Dataset loading synchronization: main process downloads first to avoid race conditions\n",
        "    cfg.dataset.episodes = episodes\n",
        "\n",
        "    if is_main_process:\n",
        "        logger.info(\"Creating dataset\")\n",
        "        dataset = make_dataset_xhuman(cfg)\n",
        "\n",
        "    accelerator.wait_for_everyone()\n",
        "\n",
        "    # Now all other processes can safely load the dataset\n",
        "    if not is_main_process:\n",
        "        dataset = make_dataset_xhuman(cfg)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KBDfTwGev8r2"
      },
      "outputs": [],
      "source": [
        "def update_policy(\n",
        "    train_metrics: MetricsTracker,\n",
        "    policy: PreTrainedPolicy,\n",
        "    batch: Any,\n",
        "    optimizer: Optimizer,\n",
        "    grad_clip_norm: float,\n",
        "    accelerator: Accelerator,\n",
        "    lr_scheduler=None,\n",
        "    lock=None,\n",
        ") -> tuple[MetricsTracker, dict]:\n",
        "    \"\"\"\n",
        "    Performs a single training step to update the policy's weights.\n",
        "\n",
        "    This function executes the forward and backward passes, clips gradients, and steps the optimizer and\n",
        "    learning rate scheduler. Accelerator handles mixed-precision training automatically.\n",
        "\n",
        "    Args:\n",
        "        train_metrics: A MetricsTracker instance to record training statistics.\n",
        "        policy: The policy model to be trained.\n",
        "        batch: A batch of training data.\n",
        "        optimizer: The optimizer used to update the policy's parameters.\n",
        "        grad_clip_norm: The maximum norm for gradient clipping.\n",
        "        accelerator: The Accelerator instance for distributed training and mixed precision.\n",
        "        lr_scheduler: An optional learning rate scheduler.\n",
        "        lock: An optional lock for thread-safe optimizer updates.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing:\n",
        "        - The updated MetricsTracker with new statistics for this step.\n",
        "        - A dictionary of outputs from the policy's forward pass, for logging purposes.\n",
        "    \"\"\"\n",
        "    start_time = time.perf_counter()\n",
        "    policy.train()\n",
        "\n",
        "    # Let accelerator handle mixed precision\n",
        "    with accelerator.autocast():\n",
        "        loss, output_dict = policy.forward(batch)\n",
        "\n",
        "    # Use accelerator's backward method\n",
        "    accelerator.backward(loss)\n",
        "\n",
        "    # Clip gradients if specified\n",
        "    if grad_clip_norm > 0:\n",
        "        grad_norm = accelerator.clip_grad_norm_(policy.parameters(), grad_clip_norm)\n",
        "    else:\n",
        "        grad_norm = torch.nn.utils.clip_grad_norm_(\n",
        "            policy.parameters(), float(\"inf\"), error_if_nonfinite=False\n",
        "        )\n",
        "\n",
        "    # Optimizer step\n",
        "    with lock if lock is not None else nullcontext():\n",
        "        optimizer.step()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Step through pytorch scheduler at every batch instead of epoch\n",
        "    if lr_scheduler is not None:\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    # Update internal buffers if policy has update method\n",
        "    if has_method(accelerator.unwrap_model(policy, keep_fp32_wrapper=True), \"update\"):\n",
        "        accelerator.unwrap_model(policy, keep_fp32_wrapper=True).update()\n",
        "\n",
        "    train_metrics.loss = loss.item()\n",
        "    train_metrics.grad_norm = grad_norm.item()\n",
        "    train_metrics.lr = optimizer.param_groups[0][\"lr\"]\n",
        "    train_metrics.update_s = time.perf_counter() - start_time\n",
        "    return train_metrics, output_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rj9VwGu3yraP"
      },
      "outputs": [],
      "source": [
        "from lerobot.policies.pi05 import PI05Config\n",
        "\n",
        "policy_config = PI05Config(repo_id=\"none\",device=\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipXWi5oev8r2"
      },
      "source": [
        "## Configuration and Setup\n",
        "\n",
        "Configure your dataset and policy settings here. The dataset configuration specifies which HuggingFace repository to load, and the policy configuration sets up the PI05 model architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEbEEWDbzMPT"
      },
      "outputs": [],
      "source": [
        "from xhuman.configs.default import LerobotDatasetConfig\n",
        "\n",
        "dataset_config = LerobotDatasetConfig(\n",
        "    repo_id=\"NONHUMAN-RESEARCH/pick-and-place-fruits-v2-test\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "IZ1d9a3Ov8r3"
      },
      "outputs": [],
      "source": [
        "# Load configuration (you can modify this to load from a config file or set directly)\n",
        "# Example: cfg = TrainPipelineConfigXHUMAN.from_dict({...})\n",
        "# For now, we'll use the parser to load from command line or config file\n",
        "# In notebook, you might want to set cfg directly\n",
        "\n",
        "\n",
        "cfg = TrainPipelineConfigXHUMAN(\n",
        "    dataset=dataset_config,\n",
        "    policy=policy_config # Example policy configuration, replace with your actual policy path\n",
        ")\n",
        "cfg.validate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgSIm33Qv8r3"
      },
      "source": [
        "## Training Setup\n",
        "\n",
        "Initialize the Accelerator for distributed training and set up the training environment. The accelerator automatically handles:\n",
        "- Multi-GPU training\n",
        "- Mixed precision training\n",
        "- Gradient synchronization across processes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "XOJhp41Sv8r4"
      },
      "outputs": [],
      "source": [
        "# Create Accelerator\n",
        "# It will automatically detect if running in distributed mode or single-process mode\n",
        "# We set step_scheduler_with_optimizer=False to prevent accelerate from adjusting the lr_scheduler steps based on the num_processes\n",
        "# We set find_unused_parameters=True to handle models with conditional computation\n",
        "ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)\n",
        "accelerator = Accelerator(step_scheduler_with_optimizer=False, kwargs_handlers=[ddp_kwargs])\n",
        "\n",
        "init_logging(accelerator=accelerator)\n",
        "\n",
        "# Determine if this is the main process (for logging and checkpointing)\n",
        "is_main_process = accelerator.is_main_process\n",
        "\n",
        "# Set seed if specified\n",
        "if cfg.seed is not None:\n",
        "    set_seed(cfg.seed, accelerator=accelerator)\n",
        "\n",
        "# Use accelerator's device\n",
        "device = accelerator.device\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cuda.matmul.allow_tf32 = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "b5534fae17eb4e90af322a736ea7442e",
            "38275ec3c52c44c4a02bde6e4ef897a6",
            "92e64a6dec1348cd96a061c82850535a",
            "533e270817314c7288c2744ae86ca25d",
            "761fb6d104a44bec957248b3d0980f09",
            "4bd2f624c9994747a1f999acdbe3c19b",
            "4742034b2cfb487cb16662c1e50f5ddd",
            "7adeb3a214d04e5b935a9a4322cfb6ce",
            "73cc3a56ad2a494198e45e648a7065c4",
            "c96f7e912b2f41cfa7b91d8f8817e129",
            "1f05cf45fc07478f9d2bc043b4582037"
          ]
        },
        "id": "s_gB_Dpbv8r5",
        "outputId": "2b15e168-a86a-4254-ab71-3321c8667f32"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:35:32] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Creating dataset                                                  <a href=\"file:///tmp/ipython-input-2227881245.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-2227881245.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-2227881245.py#3\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[22:35:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Creating dataset                                                  \u001b]8;id=31244;file:///tmp/ipython-input-2227881245.py\u001b\\\u001b[2mipython-input-2227881245.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=98246;file:///tmp/ipython-input-2227881245.py#3\u001b\\\u001b[2m3\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5534fae17eb4e90af322a736ea7442e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Loading train dataset with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> episodes                            <a href=\"file:///tmp/ipython-input-2227881245.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-2227881245.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-2227881245.py#21\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Loading train dataset with \u001b[1;36m3\u001b[0m episodes                            \u001b]8;id=709570;file:///tmp/ipython-input-2227881245.py\u001b\\\u001b[2mipython-input-2227881245.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipython-input-2227881245.py#21\u001b\\\u001b[2m21\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# Dataset Loading with Episode Filtering\n",
        "# ============================================================================\n",
        "# This cell loads the dataset with proper episode filtering.\n",
        "# For debugging: Set DEBUG_MODE = True to use only a subset of episodes\n",
        "# For production: Set DEBUG_MODE = False to use all available episodes\n",
        "\n",
        "DEBUG_MODE = True  # Set to False for full training\n",
        "DEBUG_MAX_EPISODES = 3  # Use only first N episodes for debugging\n",
        "\n",
        "# First, get total episodes count (load minimal dataset to check)\n",
        "if is_main_process:\n",
        "    temp_dataset = make_dataset_xhuman(cfg)\n",
        "    total_episodes = temp_dataset.meta.total_episodes\n",
        "    del temp_dataset\n",
        "    logger.info(f\"Total episodes available: {total_episodes}\")\n",
        "else:\n",
        "    # For non-main processes, use a reasonable default\n",
        "    # In practice, this will be synced after main process loads\n",
        "    total_episodes = 4  # Fallback - adjust if needed\n",
        "\n",
        "accelerator.wait_for_everyone()\n",
        "\n",
        "# Limit episodes for debugging\n",
        "if DEBUG_MODE:\n",
        "    episodes = list(range(min(DEBUG_MAX_EPISODES, total_episodes)))\n",
        "    if is_main_process:\n",
        "        logger.info(f\"DEBUG MODE: Using only {len(episodes)} episodes\")\n",
        "else:\n",
        "    episodes = list(range(total_episodes))\n",
        "\n",
        "# Split episodes\n",
        "train_episodes, eval_episodes = split_train_eval_episodes(\n",
        "    episodes, split_ratio=cfg.split_ratio, seed=42\n",
        ")\n",
        "\n",
        "# Load dataset with ONLY train episodes (proper way to filter)\n",
        "# This uses the load_dataset helper function which sets cfg.dataset.episodes\n",
        "if is_main_process:\n",
        "    logger.info(f\"Loading train dataset with {len(train_episodes)} episodes\")\n",
        "dataset = load_dataset(cfg, train_episodes, is_main_process=is_main_process, accelerator=accelerator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "L2T_kvevv8r6",
        "outputId": "bb065702-eff5-4d62-f738-06f7cb38fccd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:52:15] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Creating policy                                                   <a href=\"file:///tmp/ipython-input-3499831122.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-3499831122.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-3499831122.py#3\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[19:52:15]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Creating policy                                                   \u001b]8;id=655420;file:///tmp/ipython-input-3499831122.py\u001b\\\u001b[2mipython-input-3499831122.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=618439;file:///tmp/ipython-input-3499831122.py#3\u001b\\\u001b[2m3\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Create policy\n",
        "if is_main_process:\n",
        "    logger.info(\"Creating policy\")\n",
        "policy = make_xhuman_policy(\n",
        "    cfg=cfg.policy,\n",
        "    ds_meta=dataset.meta,\n",
        ")\n",
        "\n",
        "accelerator.wait_for_everyone()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WeVjdudv8r6"
      },
      "source": [
        "## Dataset and Model Information\n",
        "\n",
        "Display metadata about the loaded dataset and model. This includes:\n",
        "- Total number of episodes and frames\n",
        "- Model parameter counts\n",
        "- Effective batch size (accounting for distributed training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4cFEE9pv8r6",
        "outputId": "3d1f44e9-2fe9-447a-feef-f9e97260c8a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "DATASET METADATA\n",
            "================================================================================\n",
            "\n",
            "Dataset Repository: NONHUMAN-RESEARCH/TEST_RECORD_ANNOTATIONS\n",
            "Total Episodes: 4\n",
            "Training Episodes: 3\n",
            "Number of Frames: 1,866\n",
            "Number of Episodes (loaded): 3\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Display dataset metadata and model configuration\n",
        "if is_main_process:\n",
        "    from pprint import pprint\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"DATASET METADATA\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"\\nDataset Repository: {dataset.repo_id}\")\n",
        "    print(f\"Total Episodes: {dataset.meta.total_episodes}\")\n",
        "    print(f\"Training Episodes: {len(train_episodes)}\")\n",
        "    print(f\"Number of Frames: {dataset.num_frames:,}\")\n",
        "    print(f\"Number of Episodes (loaded): {dataset.num_episodes}\")\n",
        "\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "ADIBf_oF0T0_"
      },
      "outputs": [],
      "source": [
        "processor_kwargs = {}\n",
        "postprocessor_kwargs = {}\n",
        "\n",
        "if (cfg.policy.pretrained_path and not cfg.resume) or not cfg.policy.pretrained_path:\n",
        "    processor_kwargs[\"dataset_stats\"] = dataset.meta.stats\n",
        "\n",
        "if cfg.policy.pretrained_path is not None:\n",
        "    processor_kwargs[\"preprocessor_overrides\"] = {\n",
        "        \"device_processor\": {\"device\": device.type},\n",
        "        \"normalizer_processor\": {\n",
        "            \"stats\": dataset.meta.stats,\n",
        "            \"features\": {**policy.config.input_features, **policy.config.output_features},\n",
        "            \"norm_map\": policy.config.normalization_mapping,\n",
        "        },\n",
        "    }\n",
        "    postprocessor_kwargs[\"postprocessor_overrides\"] = {\n",
        "        \"unnormalizer_processor\": {\n",
        "            \"stats\": dataset.meta.stats,\n",
        "            \"features\": policy.config.output_features,\n",
        "            \"norm_map\": policy.config.normalization_mapping,\n",
        "        },\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suwirY3L1HHQ"
      },
      "outputs": [],
      "source": [
        "# This cell was removed - autoreload is not needed for production training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcEUR_P1v8r7",
        "outputId": "c9836d32-3e2b-407d-ba43-084e8512988c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'lerobot.policies.act.configuration_act.ACTConfig'>\n",
            "PI05Config(n_obs_steps=1, input_features={'observation.state': PolicyFeature(type=<FeatureType.STATE: 'STATE'>, shape=(14,)), 'observation.images.left': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 376, 672)), 'observation.images.top': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 376, 672)), 'observation.images.right': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 376, 672))}, output_features={'action': PolicyFeature(type=<FeatureType.ACTION: 'ACTION'>, shape=(14,))}, device='cuda', use_amp=False, use_peft=False, push_to_hub=True, repo_id='none', private=None, tags=None, license=None, pretrained_path=None, paligemma_variant='gemma_2b', action_expert_variant='gemma_300m', dtype='float32', chunk_size=50, n_action_steps=50, max_state_dim=32, max_action_dim=32, num_inference_steps=10, time_sampling_beta_alpha=1.5, time_sampling_beta_beta=1.0, time_sampling_scale=0.999, time_sampling_offset=0.001, min_period=0.004, max_period=4.0, rtc_config=None, image_resolution=(224, 224), empty_cameras=0, tokenizer_max_length=200, normalization_mapping={'VISUAL': <NormalizationMode.IDENTITY: 'IDENTITY'>, 'STATE': <NormalizationMode.QUANTILES: 'QUANTILES'>, 'ACTION': <NormalizationMode.QUANTILES: 'QUANTILES'>}, gradient_checkpointing=False, compile_model=False, compile_mode='max-autotune', freeze_vision_encoder=False, train_expert_only=False, optimizer_lr=2.5e-05, optimizer_betas=(0.9, 0.95), optimizer_eps=1e-08, optimizer_weight_decay=0.01, optimizer_grad_clip_norm=1.0, scheduler_warmup_steps=1000, scheduler_decay_steps=30000, scheduler_decay_lr=2.5e-06)\n",
            "<class 'lerobot.policies.diffusion.configuration_diffusion.DiffusionConfig'>\n",
            "PI05Config(n_obs_steps=1, input_features={'observation.state': PolicyFeature(type=<FeatureType.STATE: 'STATE'>, shape=(14,)), 'observation.images.left': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 376, 672)), 'observation.images.top': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 376, 672)), 'observation.images.right': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 376, 672))}, output_features={'action': PolicyFeature(type=<FeatureType.ACTION: 'ACTION'>, shape=(14,))}, device='cuda', use_amp=False, use_peft=False, push_to_hub=True, repo_id='none', private=None, tags=None, license=None, pretrained_path=None, paligemma_variant='gemma_2b', action_expert_variant='gemma_300m', dtype='float32', chunk_size=50, n_action_steps=50, max_state_dim=32, max_action_dim=32, num_inference_steps=10, time_sampling_beta_alpha=1.5, time_sampling_beta_beta=1.0, time_sampling_scale=0.999, time_sampling_offset=0.001, min_period=0.004, max_period=4.0, rtc_config=None, image_resolution=(224, 224), empty_cameras=0, tokenizer_max_length=200, normalization_mapping={'VISUAL': <NormalizationMode.IDENTITY: 'IDENTITY'>, 'STATE': <NormalizationMode.QUANTILES: 'QUANTILES'>, 'ACTION': <NormalizationMode.QUANTILES: 'QUANTILES'>}, gradient_checkpointing=False, compile_model=False, compile_mode='max-autotune', freeze_vision_encoder=False, train_expert_only=False, optimizer_lr=2.5e-05, optimizer_betas=(0.9, 0.95), optimizer_eps=1e-08, optimizer_weight_decay=0.01, optimizer_grad_clip_norm=1.0, scheduler_warmup_steps=1000, scheduler_decay_steps=30000, scheduler_decay_lr=2.5e-06)\n",
            "<class 'lerobot.policies.pi0.configuration_pi0.PI0Config'>\n",
            "PI05Config(n_obs_steps=1, input_features={'observation.state': PolicyFeature(type=<FeatureType.STATE: 'STATE'>, shape=(14,)), 'observation.images.left': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 376, 672)), 'observation.images.top': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 376, 672)), 'observation.images.right': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 376, 672))}, output_features={'action': PolicyFeature(type=<FeatureType.ACTION: 'ACTION'>, shape=(14,))}, device='cuda', use_amp=False, use_peft=False, push_to_hub=True, repo_id='none', private=None, tags=None, license=None, pretrained_path=None, paligemma_variant='gemma_2b', action_expert_variant='gemma_300m', dtype='float32', chunk_size=50, n_action_steps=50, max_state_dim=32, max_action_dim=32, num_inference_steps=10, time_sampling_beta_alpha=1.5, time_sampling_beta_beta=1.0, time_sampling_scale=0.999, time_sampling_offset=0.001, min_period=0.004, max_period=4.0, rtc_config=None, image_resolution=(224, 224), empty_cameras=0, tokenizer_max_length=200, normalization_mapping={'VISUAL': <NormalizationMode.IDENTITY: 'IDENTITY'>, 'STATE': <NormalizationMode.QUANTILES: 'QUANTILES'>, 'ACTION': <NormalizationMode.QUANTILES: 'QUANTILES'>}, gradient_checkpointing=False, compile_model=False, compile_mode='max-autotune', freeze_vision_encoder=False, train_expert_only=False, optimizer_lr=2.5e-05, optimizer_betas=(0.9, 0.95), optimizer_eps=1e-08, optimizer_weight_decay=0.01, optimizer_grad_clip_norm=1.0, scheduler_warmup_steps=1000, scheduler_decay_steps=30000, scheduler_decay_lr=2.5e-06)\n",
            "<class 'xhuman.policies.pi05.configuration_pi05.PI05Config'>\n",
            "PI05Config(n_obs_steps=1, input_features={'observation.state': PolicyFeature(type=<FeatureType.STATE: 'STATE'>, shape=(14,)), 'observation.images.left': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 376, 672)), 'observation.images.top': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 376, 672)), 'observation.images.right': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 376, 672))}, output_features={'action': PolicyFeature(type=<FeatureType.ACTION: 'ACTION'>, shape=(14,))}, device='cuda', use_amp=False, use_peft=False, push_to_hub=True, repo_id='none', private=None, tags=None, license=None, pretrained_path=None, paligemma_variant='gemma_2b', action_expert_variant='gemma_300m', dtype='float32', chunk_size=50, n_action_steps=50, max_state_dim=32, max_action_dim=32, num_inference_steps=10, time_sampling_beta_alpha=1.5, time_sampling_beta_beta=1.0, time_sampling_scale=0.999, time_sampling_offset=0.001, min_period=0.004, max_period=4.0, rtc_config=None, image_resolution=(224, 224), empty_cameras=0, tokenizer_max_length=200, normalization_mapping={'VISUAL': <NormalizationMode.IDENTITY: 'IDENTITY'>, 'STATE': <NormalizationMode.QUANTILES: 'QUANTILES'>, 'ACTION': <NormalizationMode.QUANTILES: 'QUANTILES'>}, gradient_checkpointing=False, compile_model=False, compile_mode='max-autotune', freeze_vision_encoder=False, train_expert_only=False, optimizer_lr=2.5e-05, optimizer_betas=(0.9, 0.95), optimizer_eps=1e-08, optimizer_weight_decay=0.01, optimizer_grad_clip_norm=1.0, scheduler_warmup_steps=1000, scheduler_decay_steps=30000, scheduler_decay_lr=2.5e-06)\n",
            "<class 'lerobot.policies.pi05.configuration_pi05.PI05Config'>\n",
            "PI05Config(n_obs_steps=1, input_features={'observation.state': PolicyFeature(type=<FeatureType.STATE: 'STATE'>, shape=(14,)), 'observation.images.left': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 376, 672)), 'observation.images.top': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 376, 672)), 'observation.images.right': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 376, 672))}, output_features={'action': PolicyFeature(type=<FeatureType.ACTION: 'ACTION'>, shape=(14,))}, device='cuda', use_amp=False, use_peft=False, push_to_hub=True, repo_id='none', private=None, tags=None, license=None, pretrained_path=None, paligemma_variant='gemma_2b', action_expert_variant='gemma_300m', dtype='float32', chunk_size=50, n_action_steps=50, max_state_dim=32, max_action_dim=32, num_inference_steps=10, time_sampling_beta_alpha=1.5, time_sampling_beta_beta=1.0, time_sampling_scale=0.999, time_sampling_offset=0.001, min_period=0.004, max_period=4.0, rtc_config=None, image_resolution=(224, 224), empty_cameras=0, tokenizer_max_length=200, normalization_mapping={'VISUAL': <NormalizationMode.IDENTITY: 'IDENTITY'>, 'STATE': <NormalizationMode.QUANTILES: 'QUANTILES'>, 'ACTION': <NormalizationMode.QUANTILES: 'QUANTILES'>}, gradient_checkpointing=False, compile_model=False, compile_mode='max-autotune', freeze_vision_encoder=False, train_expert_only=False, optimizer_lr=2.5e-05, optimizer_betas=(0.9, 0.95), optimizer_eps=1e-08, optimizer_weight_decay=0.01, optimizer_grad_clip_norm=1.0, scheduler_warmup_steps=1000, scheduler_decay_steps=30000, scheduler_decay_lr=2.5e-06)\n"
          ]
        }
      ],
      "source": [
        "# Create processors\n",
        "preprocessor, postprocessor = make_xhuman_pre_post_processors(\n",
        "    policy_cfg=cfg.policy,\n",
        "    pretrained_path=cfg.policy.pretrained_path,\n",
        "    **processor_kwargs,\n",
        "    **postprocessor_kwargs,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Zj87lmHcv8r7",
        "outputId": "24d6b2bd-d8e3-4cff-f76a-2616d048f602"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:36:05] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Creating optimizer and scheduler                                  <a href=\"file:///tmp/ipython-input-1795964688.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-1795964688.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-1795964688.py#3\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[22:36:05]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Creating optimizer and scheduler                                  \u001b]8;id=442417;file:///tmp/ipython-input-1795964688.py\u001b\\\u001b[2mipython-input-1795964688.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipython-input-1795964688.py#3\u001b\\\u001b[2m3\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create optimizer and scheduler\n",
        "if is_main_process:\n",
        "    logger.info(\"Creating optimizer and scheduler\")\n",
        "optimizer, lr_scheduler = make_optimizer_and_scheduler(cfg, policy)\n",
        "\n",
        "step = 0  # number of policy updates\n",
        "\n",
        "# Resume from checkpoint if needed\n",
        "if cfg.resume:\n",
        "    step, optimizer, lr_scheduler = load_training_state(cfg.checkpoint_path, optimizer, lr_scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "E_d1t5DWv8r8",
        "outputId": "a446b354-109d-4d56-e818-9f37231d7529"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:36:10] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Output dir: outputs/train/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2026</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>-49_pi05                <a href=\"file:///tmp/ipython-input-4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-4288334519.py#5\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[22:36:10]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Output dir: outputs/train/\u001b[1;36m2026\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m13\u001b[0m/\u001b[1;36m22\u001b[0m-\u001b[1;36m33\u001b[0m-49_pi05                \u001b]8;id=529903;file:///tmp/ipython-input-4288334519.py\u001b\\\u001b[2mipython-input-4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipython-input-4288334519.py#5\u001b\\\u001b[2m5\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Steps: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100000</span> <span style=\"font-weight: bold\">(</span>100K<span style=\"font-weight: bold\">)</span>                                              <a href=\"file:///tmp/ipython-input-4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-4288334519.py#6\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Steps: \u001b[1;36m100000\u001b[0m \u001b[1m(\u001b[0m100K\u001b[1m)\u001b[0m                                              \u001b]8;id=681453;file:///tmp/ipython-input-4288334519.py\u001b\\\u001b[2mipython-input-4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///tmp/ipython-input-4288334519.py#6\u001b\\\u001b[2m6\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Dataset frames: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1866</span> <span style=\"font-weight: bold\">(</span>2K<span style=\"font-weight: bold\">)</span>                                         <a href=\"file:///tmp/ipython-input-4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-4288334519.py#7\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">7</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Dataset frames: \u001b[1;36m1866\u001b[0m \u001b[1m(\u001b[0m2K\u001b[1m)\u001b[0m                                         \u001b]8;id=617889;file:///tmp/ipython-input-4288334519.py\u001b\\\u001b[2mipython-input-4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=291704;file:///tmp/ipython-input-4288334519.py#7\u001b\\\u001b[2m7\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Dataset episodes: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>                                               <a href=\"file:///tmp/ipython-input-4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-4288334519.py#8\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Dataset episodes: \u001b[1;36m3\u001b[0m                                               \u001b]8;id=844962;file:///tmp/ipython-input-4288334519.py\u001b\\\u001b[2mipython-input-4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=167414;file:///tmp/ipython-input-4288334519.py#8\u001b\\\u001b[2m8\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Effective batch size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> x <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>                                  <a href=\"file:///tmp/ipython-input-4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-4288334519.py#11\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Effective batch size: \u001b[1;36m8\u001b[0m x \u001b[1;36m1\u001b[0m = \u001b[1;36m8\u001b[0m                                  \u001b]8;id=163032;file:///tmp/ipython-input-4288334519.py\u001b\\\u001b[2mipython-input-4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=225772;file:///tmp/ipython-input-4288334519.py#11\u001b\\\u001b[2m11\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Learnable params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3616757520</span> <span style=\"font-weight: bold\">(</span>4B<span style=\"font-weight: bold\">)</span>                                <a href=\"file:///tmp/ipython-input-4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-4288334519.py#12\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Learnable params: \u001b[1;36m3616757520\u001b[0m \u001b[1m(\u001b[0m4B\u001b[1m)\u001b[0m                                \u001b]8;id=398382;file:///tmp/ipython-input-4288334519.py\u001b\\\u001b[2mipython-input-4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=101414;file:///tmp/ipython-input-4288334519.py#12\u001b\\\u001b[2m12\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Total params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3616757520</span> <span style=\"font-weight: bold\">(</span>4B<span style=\"font-weight: bold\">)</span>                                    <a href=\"file:///tmp/ipython-input-4288334519.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-4288334519.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-4288334519.py#13\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Total params: \u001b[1;36m3616757520\u001b[0m \u001b[1m(\u001b[0m4B\u001b[1m)\u001b[0m                                    \u001b]8;id=277370;file:///tmp/ipython-input-4288334519.py\u001b\\\u001b[2mipython-input-4288334519.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=846335;file:///tmp/ipython-input-4288334519.py#13\u001b\\\u001b[2m13\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Print training info\n",
        "if is_main_process:\n",
        "    num_learnable_params = sum(p.numel() for p in policy.parameters() if p.requires_grad)\n",
        "    num_total_params = sum(p.numel() for p in policy.parameters())\n",
        "    logger.info(f\"Output dir: {cfg.output_dir}\")\n",
        "    logger.info(f\"Steps: {cfg.steps} ({format_big_number(cfg.steps)})\")\n",
        "    logger.info(f\"Dataset frames: {dataset.num_frames} ({format_big_number(dataset.num_frames)})\")\n",
        "    logger.info(f\"Dataset episodes: {dataset.num_episodes}\")\n",
        "    num_processes = accelerator.num_processes\n",
        "    effective_bs = cfg.batch_size * num_processes\n",
        "    logger.info(f\"Effective batch size: {cfg.batch_size} x {num_processes} = {effective_bs}\")\n",
        "    logger.info(f\"Learnable params: {num_learnable_params} ({format_big_number(num_learnable_params)})\")\n",
        "    logger.info(f\"Total params: {num_total_params} ({format_big_number(num_total_params)})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jAOHZFNwv8r8",
        "outputId": "bb3156e2-8f79-421a-a635-7ffd23a9a46c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:36:11] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Not dropping any frames                                          <a href=\"file:///tmp/ipython-input-2400968918.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-2400968918.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-2400968918.py#12\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[22:36:11]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Not dropping any frames                                          \u001b]8;id=130889;file:///tmp/ipython-input-2400968918.py\u001b\\\u001b[2mipython-input-2400968918.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=967096;file:///tmp/ipython-input-2400968918.py#12\u001b\\\u001b[2m12\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create dataloader\n",
        "if hasattr(cfg.policy, \"drop_n_last_frames\"):\n",
        "    logger.info(f\"Dropping {cfg.policy.drop_n_last_frames} last frames\")\n",
        "    shuffle = False\n",
        "    sampler = EpisodeAwareSampler(\n",
        "        dataset.meta.episodes[\"dataset_from_index\"],\n",
        "        dataset.meta.episodes[\"dataset_to_index\"],\n",
        "        drop_n_last_frames=cfg.policy.drop_n_last_frames,\n",
        "        shuffle=True,\n",
        "    )\n",
        "else:\n",
        "    logger.info(\"Not dropping any frames\")\n",
        "    shuffle = True\n",
        "    sampler = None\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    num_workers=cfg.num_workers,\n",
        "    batch_size=cfg.batch_size,\n",
        "    shuffle=shuffle and not cfg.dataset.streaming,\n",
        "    sampler=sampler,\n",
        "    pin_memory=device.type == \"cuda\",\n",
        "    drop_last=False,\n",
        "    prefetch_factor=2 if cfg.num_workers > 0 else None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "-PTn44Wfv8r8"
      },
      "outputs": [],
      "source": [
        "# Prepare everything with accelerator\n",
        "accelerator.wait_for_everyone()\n",
        "policy, optimizer, dataloader, lr_scheduler = accelerator.prepare(\n",
        "    policy, optimizer, dataloader, lr_scheduler\n",
        ")\n",
        "dl_iter = cycle(dataloader)\n",
        "\n",
        "policy.train()\n",
        "\n",
        "# Setup metrics tracking\n",
        "train_metrics = {\n",
        "    \"loss\": AverageMeter(\"loss\", \":.3f\"),\n",
        "    \"grad_norm\": AverageMeter(\"grdn\", \":.3f\"),\n",
        "    \"lr\": AverageMeter(\"lr\", \":0.1e\"),\n",
        "    \"update_s\": AverageMeter(\"updt_s\", \":.3f\"),\n",
        "    \"dataloading_s\": AverageMeter(\"data_s\", \":.3f\"),\n",
        "}\n",
        "\n",
        "effective_batch_size = cfg.batch_size * accelerator.num_processes\n",
        "train_tracker = MetricsTracker(\n",
        "    effective_batch_size,\n",
        "    dataset.num_frames,\n",
        "    dataset.num_episodes,\n",
        "    train_metrics,\n",
        "    initial_step=step,\n",
        "    accelerator=accelerator,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWYscS-uv8r9"
      },
      "source": [
        "## Training Loop\n",
        "\n",
        "The main training loop iterates through batches, performs forward/backward passes, and updates the policy weights. \n",
        "\n",
        "**Note**: The loop below runs for 6 steps as an example. For full training, replace with:\n",
        "```python\n",
        "while step < cfg.steps:\n",
        "    # ... training code ...\n",
        "```\n",
        "\n",
        "Metrics are logged at intervals specified by `cfg.log_freq`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "n7wHY5Q_7EMt",
        "outputId": "b91ea27b-13dd-48a7-9a47-455693a67d5c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:54:12] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Start offline training on a fixed dataset                         <a href=\"file:///tmp/ipython-input-1178716464.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-1178716464.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-1178716464.py#2\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[19:54:12]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Start offline training on a fixed dataset                         \u001b]8;id=168637;file:///tmp/ipython-input-1178716464.py\u001b\\\u001b[2mipython-input-1178716464.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=345824;file:///tmp/ipython-input-1178716464.py#2\u001b\\\u001b[2m2\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Train episodes: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">796</span>                                               <a href=\"file:///tmp/ipython-input-1178716464.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ipython-input-1178716464.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipython-input-1178716464.py#3\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mINFO    \u001b[0m Train episodes: \u001b[1;36m796\u001b[0m                                               \u001b]8;id=991107;file:///tmp/ipython-input-1178716464.py\u001b\\\u001b[2mipython-input-1178716464.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=419904;file:///tmp/ipython-input-1178716464.py#3\u001b\\\u001b[2m3\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Training initialization\n",
        "# This logs the start of training and shows how many episodes will be used\n",
        "if is_main_process:\n",
        "    logger.info(\"Start offline training on a fixed dataset\")\n",
        "    logger.info(f\"Train episodes: {len(train_episodes)}\")\n",
        "    logger.info(f\"Total training steps: {cfg.steps}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "ky4jT3NIXSMO"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SmartSubset(Dataset):\n",
        "    def __init__(self, dataset, indices):\n",
        "        self.dataset = dataset\n",
        "        self.indices = indices\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.dataset[self.indices[idx]]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getattr__(self, name):\n",
        "        # This is the magic part:\n",
        "        # If the code asks for 'meta', 'fps', etc., and this class doesn't have it,\n",
        "        # it automatically looks inside the original dataset.\n",
        "        return getattr(self.dataset, name)\n",
        "\n",
        "# --- USAGE ---\n",
        "# Use SmartSubset instead of torch.utils.data.Subset\n",
        "debug_subset = SmartSubset(dataset, range(0, 50))\n",
        "\n",
        "# Now create your loader normally\n",
        "train_dataloader = DataLoader(\n",
        "    debug_subset,\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "dl_iter = iter(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "mFQNLAl-Qr3T",
        "outputId": "7b3234ad-4128-4c2e-c4f8-e1cd49c4f9ed"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "7",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/content/XHUMAN/xhuman/datasets/xhuman_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;31m# Try to load the requested frames normally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mquery_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query_hf_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lerobot/datasets/lerobot_dataset.py\u001b[0m in \u001b[0;36m_query_hf_dataset\u001b[0;34m(self, query_indices)\u001b[0m\n\u001b[1;32m    992\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_absolute_to_relative_idx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m                 \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_absolute_to_relative_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mq_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m             )\n",
            "\u001b[0;31mKeyError\u001b[0m: 1089",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2637603158.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# --- SAFE ITERATOR LOGIC ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mbatch_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# We finished the 50 items! Restart from the beginning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/XHUMAN/xhuman/datasets/xhuman_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0msafe_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0mquery_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query_hf_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0;31m# --- END FIX ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lerobot/datasets/lerobot_dataset.py\u001b[0m in \u001b[0;36m_query_hf_dataset\u001b[0;34m(self, query_indices)\u001b[0m\n\u001b[1;32m    991\u001b[0m                 \u001b[0mq_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_absolute_to_relative_idx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m                 \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_absolute_to_relative_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mq_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m             )\n\u001b[1;32m    995\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 7"
          ]
        }
      ],
      "source": [
        "for step in range(0, 2): # Or however many steps you want\n",
        "    # --- SAFE ITERATOR LOGIC ---\n",
        "    try:\n",
        "        batch_ = next(dl_iter)\n",
        "    except StopIteration:\n",
        "        # We finished the 50 items! Restart from the beginning.\n",
        "        dl_iter = iter(train_dataloader)\n",
        "        batch_ = next(dl_iter)\n",
        "    start_time = time.perf_counter()\n",
        "    batch = preprocessor(batch_)\n",
        "\n",
        "    print(batch)\n",
        "\n",
        "    train_tracker, output_dict = update_policy(\n",
        "        train_tracker,\n",
        "        policy,\n",
        "        batch,\n",
        "        optimizer,\n",
        "        cfg.optimizer.grad_clip_norm,\n",
        "        accelerator=accelerator,\n",
        "        lr_scheduler=lr_scheduler,\n",
        "    )\n",
        "    print(train_tracker)\n",
        "    print(output_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "__oz7KtM73-t"
      },
      "outputs": [],
      "source": [
        "dl_iter = iter(dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Completion\n",
        "\n",
        "After the training loop completes, metrics are logged and the accelerator is cleaned up. \n",
        "\n",
        "**Note**: Any debug cells below this point (if present) can be ignored - they were used during development to test dataset subsetting approaches. The proper way to filter episodes is now handled via `DEBUG_MODE` in the dataset loading cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "id": "fBQ4uVFPv8r9",
        "outputId": "885ff7f6-5a8b-4f8b-c58b-4c157bfbd288"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "Caught KeyError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"/content/XHUMAN/xhuman/datasets/xhuman_dataset.py\", line 156, in __getitem__\n    query_result = self._query_hf_dataset(query_indices)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/lerobot/datasets/lerobot_dataset.py\", line 993, in _query_hf_dataset\n    else [self._absolute_to_relative_idx[idx] for idx in q_idx]\n          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^\nKeyError: 42377\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/content/XHUMAN/xhuman/datasets/xhuman_dataset.py\", line 166, in __getitem__\n    query_result = self._query_hf_dataset(safe_indices)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/lerobot/datasets/lerobot_dataset.py\", line 993, in _query_hf_dataset\n    else [self._absolute_to_relative_idx[idx] for idx in q_idx]\n          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^\nKeyError: 42377\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3394350883.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    577\u001b[0m                     \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m                 \u001b[0mnext_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mcurrent_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1486\u001b[0m                 \u001b[0mworker_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1488\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data, worker_idx)\u001b[0m\n\u001b[1;32m   1548\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1551\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0;31m# be constructed, don't try to instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"/content/XHUMAN/xhuman/datasets/xhuman_dataset.py\", line 156, in __getitem__\n    query_result = self._query_hf_dataset(query_indices)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/lerobot/datasets/lerobot_dataset.py\", line 993, in _query_hf_dataset\n    else [self._absolute_to_relative_idx[idx] for idx in q_idx]\n          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^\nKeyError: 42377\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/content/XHUMAN/xhuman/datasets/xhuman_dataset.py\", line 166, in __getitem__\n    query_result = self._query_hf_dataset(safe_indices)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/lerobot/datasets/lerobot_dataset.py\", line 993, in _query_hf_dataset\n    else [self._absolute_to_relative_idx[idx] for idx in q_idx]\n          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^\nKeyError: 42377\n"
          ]
        }
      ],
      "source": [
        "# Main training loop\n",
        "# Replace the range(0, 6) with while step < cfg.steps: for full training\n",
        "if is_main_process:\n",
        "    logger.info(\"Starting training loop\")\n",
        "\n",
        "while step < cfg.steps:\n",
        "    # Measure data loading time\n",
        "    start_time = time.perf_counter()\n",
        "    batch = next(dl_iter)\n",
        "    batch = preprocessor(batch)\n",
        "    train_tracker.dataloading_s = time.perf_counter() - start_time\n",
        "\n",
        "    # Update policy (forward pass, backward pass, optimizer step)\n",
        "    train_tracker, output_dict = update_policy(\n",
        "        train_tracker,\n",
        "        policy,\n",
        "        batch,\n",
        "        optimizer,\n",
        "        cfg.optimizer.grad_clip_norm,\n",
        "        accelerator=accelerator,\n",
        "        lr_scheduler=lr_scheduler,\n",
        "    )\n",
        "\n",
        "    step += 1\n",
        "    train_tracker.step()\n",
        "\n",
        "    # Log metrics at specified intervals\n",
        "    is_log_step = cfg.log_freq > 0 and step % cfg.log_freq == 0 and is_main_process\n",
        "    if is_log_step:\n",
        "        logger.info(train_tracker)\n",
        "        train_tracker.reset_averages()\n",
        "\n",
        "    # Optional: Add checkpoint saving here\n",
        "    # if cfg.checkpoint_freq > 0 and step % cfg.checkpoint_freq == 0:\n",
        "    #     save_checkpoint(...)\n",
        "\n",
        "if is_main_process:\n",
        "    logger.info(f\"Training completed! Total steps: {step}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIKpqlbJv8r9"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Cleanup\n",
        "# ============================================================================\n",
        "# Synchronize all processes and clean up accelerator resources\n",
        "accelerator.wait_for_everyone()\n",
        "accelerator.end_training()\n",
        "\n",
        "if is_main_process:\n",
        "    logger.info(\"Training session ended successfully\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1f05cf45fc07478f9d2bc043b4582037": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "223635f477ae4dd1979d9ccffedf217c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_e32221c2a4c54597a0055f310d820f18"
          }
        },
        "24715984bee94afaa73dee4cb075ca61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c00b0e1ccb84d738efb8b7edbab1ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2b69de2f22d481d835951be4082c268",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a5ddfc2dbeda4962b3eefedf942570b9",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "34f50fe3202c4af9950768fb2e3adb44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24715984bee94afaa73dee4cb075ca61",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8c297db32b614e08983c241e91d3027f",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "38275ec3c52c44c4a02bde6e4ef897a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bd2f624c9994747a1f999acdbe3c19b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4742034b2cfb487cb16662c1e50f5ddd",
            "value": "Fetchingâ€‡8â€‡files:â€‡100%"
          }
        },
        "4742034b2cfb487cb16662c1e50f5ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bd2f624c9994747a1f999acdbe3c19b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f51c0d79c4f460fb2bf4032f85dd059": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "5061f9c62d9b47d8acc7ecfd1209035e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "533e270817314c7288c2744ae86ca25d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c96f7e912b2f41cfa7b91d8f8817e129",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1f05cf45fc07478f9d2bc043b4582037",
            "value": "â€‡8/8â€‡[00:00&lt;00:00,â€‡521.46it/s]"
          }
        },
        "58f5a99f270e4ae299031956a56a4bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59e7d62281b247e283295f66340518e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b059a56590b42f89cc4dab7f9a39c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_f87e9e5fe39043c782fc5b97d7481a45",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_59e7d62281b247e283295f66340518e6",
            "value": ""
          }
        },
        "73cc3a56ad2a494198e45e648a7065c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75c051939f5545929beedce2030d65d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58f5a99f270e4ae299031956a56a4bdc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5061f9c62d9b47d8acc7ecfd1209035e",
            "value": "Connecting..."
          }
        },
        "761fb6d104a44bec957248b3d0980f09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7adeb3a214d04e5b935a9a4322cfb6ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ba69367713444238891a999e4f4edc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_83e28ff7d8084a66afd78d2309b63f85",
            "style": "IPY_MODEL_4f51c0d79c4f460fb2bf4032f85dd059",
            "tooltip": ""
          }
        },
        "83e28ff7d8084a66afd78d2309b63f85": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c297db32b614e08983c241e91d3027f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92e64a6dec1348cd96a061c82850535a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7adeb3a214d04e5b935a9a4322cfb6ce",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73cc3a56ad2a494198e45e648a7065c4",
            "value": 8
          }
        },
        "977753a82157430f96b7edd621de13d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_cf300958c285470fb4f5727bbbaf6364",
            "style": "IPY_MODEL_c3f4563188db4314bdeb9fa74801e238",
            "value": true
          }
        },
        "a5ddfc2dbeda4962b3eefedf942570b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5534fae17eb4e90af322a736ea7442e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38275ec3c52c44c4a02bde6e4ef897a6",
              "IPY_MODEL_92e64a6dec1348cd96a061c82850535a",
              "IPY_MODEL_533e270817314c7288c2744ae86ca25d"
            ],
            "layout": "IPY_MODEL_761fb6d104a44bec957248b3d0980f09"
          }
        },
        "c3f4563188db4314bdeb9fa74801e238": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c96f7e912b2f41cfa7b91d8f8817e129": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf300958c285470fb4f5727bbbaf6364": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2b69de2f22d481d835951be4082c268": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e32221c2a4c54597a0055f310d820f18": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "f87e9e5fe39043c782fc5b97d7481a45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
